{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15120, 1)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "DATA_PATH = '../data/'\n",
    "filename  = 'estrepublicain_annee_1999.csv'\n",
    "\n",
    "df = pd.read_csv(DATA_PATH + filename)\n",
    "# df = df[0:1000]\n",
    "\n",
    "# sampler \n",
    "\n",
    "df = df.sample(frac= 0.5)\n",
    "df.reset_index(inplace = True, drop = True)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "= dimensions\n",
      "(15120, 1)\n",
      "= 5 premieres rangés\n",
      "                                                text\n",
      "0  Le chemin longe les nombreux bassins d'élevage...\n",
      "1  Le secours et le salut des âmes pour les habit...\n",
      "2  L'association « Le Haut Fer » organise deux ma...\n",
      "3  On les trouve très actifs en ce moment les jeu...\n",
      "4  NANCY. - La dernière épreuve venait de boucler...\n",
      "= Noms des colonnes\n",
      "Index(['text'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df\n",
    "print(\"= dimensions\")\n",
    "print(df.shape)\n",
    "print(\"= 5 premieres rangés\")\n",
    "print(df.head())\n",
    "print(\"= Noms des colonnes\")\n",
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['paragraphe'], dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Changer le nom de la colonne\n",
    "df.columns = ['paragraphe']\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['text'], dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# puis renommer colonne en 'text'\n",
    "\n",
    "df.columns = ['text']\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ne prendre que les 1000 premieres rangées\n",
    "\n",
    "# print(\"avant: {}\".format(df.shape))\n",
    "# df = df[0:1000]\n",
    "\n",
    "# print(\"apres: {}\".format(df.shape))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['les', 'médiateurs', 'confirment', '«', \"l'absence\", 'de', 'solution', 'parfaite', '»', '.']\n",
      "['les', 'médiateurs', 'confirment', '«', \"l'absence\", 'de', 'solution', 'parfaite', '».', '']\n"
     ]
    }
   ],
   "source": [
    "# Tokenization\n",
    "from nltk import word_tokenize\n",
    "\n",
    "# La phrase\n",
    "sentence = \"les médiateurs confirment « l'absence de solution parfaite ». \"\n",
    "\n",
    "tokens = word_tokenize(sentence)\n",
    "\n",
    "print(tokens)\n",
    "tokens_on_space = sentence.split(' ')\n",
    "print(tokens_on_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liste original de signe de ponctuations\n",
      "\t!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n",
      "{'!': ' ', '\"': ' ', '#': ' ', '$': ' ', '%': ' ', '&': ' ', \"'\": ' ', '(': ' ', ')': ' ', '*': ' ', '+': ' ', ',': ' ', '-': ' ', '.': ' ', '/': ' ', ':': ' ', ';': ' ', '<': ' ', '=': ' ', '>': ' ', '?': ' ', '@': ' ', '[': ' ', '\\\\': ' ', ']': ' ', '^': ' ', '_': ' ', '`': ' ', '{': ' ', '|': ' ', '}': ' ', '~': ' ', '«': ' ', '»': ' '}\n",
      "les médiateurs confirment « l'absence de solution parfaite ». \n",
      "les médiateurs confirment   l absence de solution parfaite    \n"
     ]
    }
   ],
   "source": [
    "# ponctuation\n",
    "\n",
    "import string\n",
    "\n",
    "print(\"Liste original de signe de ponctuations\")\n",
    "print(\"\\t{}\".format(string.punctuation))\n",
    "\n",
    "sentence = \"les médiateurs confirment « l'absence de solution parfaite ». \"\n",
    "punctuation_chars = string.punctuation + \"«»\"\n",
    "\n",
    "#  Construction d'un dict { '~':' ', '$': ' ', ... }\n",
    "dict_ponctuation = {}\n",
    "for k in punctuation_chars:\n",
    "    dict_ponctuation[k] = ' '\n",
    "\n",
    "print(dict_ponctuation)\n",
    "\n",
    "# # L'operateur de translation\n",
    "translator = str.maketrans(dict_ponctuation)\n",
    "\n",
    "new_sentence = sentence.translate(translator)\n",
    "print(sentence)\n",
    "print(new_sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['les', 'médiateurs', 'confirment', 'l', 'absence', 'de', 'solution', 'parfaite']\n",
      "['médiateurs', 'confirment', 'absence', 'solution', 'parfaite']\n"
     ]
    }
   ],
   "source": [
    "# stopwords\n",
    "tokens = word_tokenize(new_sentence)\n",
    "print(tokens)\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "# print(\"=== stopwords - français:\")\n",
    "# print(sorted(stopwords.words('french')))\n",
    "\n",
    "list_stopwords = stopwords.words('french') + ['les', 'de']\n",
    "\n",
    "# # equivalent:\n",
    "# stopwords = stopwords.words('french')\n",
    "# stopwords.append('les')\n",
    "# stopwords.append('de')\n",
    "\n",
    "\n",
    "# \n",
    "tokens_sans_stopwords = [w for w in tokens if (w not in list_stopwords) ]\n",
    "\n",
    "## Equivalent \n",
    "tokens_sans_stopwords = []\n",
    "for w in tokens:\n",
    "    if w not in list_stopwords:\n",
    "        tokens_sans_stopwords.append(w)\n",
    "\n",
    "\n",
    "\n",
    "print(tokens_sans_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_no_punctuation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Le chemin longe les nombreux bassins d'élevage...</td>\n",
       "      <td>Le chemin longe les nombreux bassins d élevage...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Le secours et le salut des âmes pour les habit...</td>\n",
       "      <td>Le secours et le salut des âmes pour les habit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>L'association « Le Haut Fer » organise deux ma...</td>\n",
       "      <td>L association   Le Haut Fer   organise deux ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>On les trouve très actifs en ce moment les jeu...</td>\n",
       "      <td>On les trouve très actifs en ce moment les jeu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NANCY. - La dernière épreuve venait de boucler...</td>\n",
       "      <td>NANCY    La dernière épreuve venait de boucler...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Le chemin longe les nombreux bassins d'élevage...   \n",
       "1  Le secours et le salut des âmes pour les habit...   \n",
       "2  L'association « Le Haut Fer » organise deux ma...   \n",
       "3  On les trouve très actifs en ce moment les jeu...   \n",
       "4  NANCY. - La dernière épreuve venait de boucler...   \n",
       "\n",
       "                                 text_no_punctuation  \n",
       "0  Le chemin longe les nombreux bassins d élevage...  \n",
       "1  Le secours et le salut des âmes pour les habit...  \n",
       "2  L association   Le Haut Fer   organise deux ma...  \n",
       "3  On les trouve très actifs en ce moment les jeu...  \n",
       "4  NANCY    La dernière épreuve venait de boucler...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Enlevons la ponctuation\n",
    "\n",
    "df['text_no_punctuation'] = df.text.apply(lambda \n",
    "    r : ( r.translate(translator) ) \n",
    ")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_no_punctuation</th>\n",
       "      <th>tokens_all</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Le chemin longe les nombreux bassins d'élevage...</td>\n",
       "      <td>Le chemin longe les nombreux bassins d élevage...</td>\n",
       "      <td>[le, chemin, longe, les, nombreux, bassins, d,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Le secours et le salut des âmes pour les habit...</td>\n",
       "      <td>Le secours et le salut des âmes pour les habit...</td>\n",
       "      <td>[le, secours, et, le, salut, des, âmes, pour, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>L'association « Le Haut Fer » organise deux ma...</td>\n",
       "      <td>L association   Le Haut Fer   organise deux ma...</td>\n",
       "      <td>[l, association, le, haut, fer, organise, deux...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>On les trouve très actifs en ce moment les jeu...</td>\n",
       "      <td>On les trouve très actifs en ce moment les jeu...</td>\n",
       "      <td>[on, les, trouve, très, actifs, en, ce, moment...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NANCY. - La dernière épreuve venait de boucler...</td>\n",
       "      <td>NANCY    La dernière épreuve venait de boucler...</td>\n",
       "      <td>[nancy, la, dernière, épreuve, venait, de, bou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Le chemin longe les nombreux bassins d'élevage...   \n",
       "1  Le secours et le salut des âmes pour les habit...   \n",
       "2  L'association « Le Haut Fer » organise deux ma...   \n",
       "3  On les trouve très actifs en ce moment les jeu...   \n",
       "4  NANCY. - La dernière épreuve venait de boucler...   \n",
       "\n",
       "                                 text_no_punctuation  \\\n",
       "0  Le chemin longe les nombreux bassins d élevage...   \n",
       "1  Le secours et le salut des âmes pour les habit...   \n",
       "2  L association   Le Haut Fer   organise deux ma...   \n",
       "3  On les trouve très actifs en ce moment les jeu...   \n",
       "4  NANCY    La dernière épreuve venait de boucler...   \n",
       "\n",
       "                                          tokens_all  \n",
       "0  [le, chemin, longe, les, nombreux, bassins, d,...  \n",
       "1  [le, secours, et, le, salut, des, âmes, pour, ...  \n",
       "2  [l, association, le, haut, fer, organise, deux...  \n",
       "3  [on, les, trouve, très, actifs, en, ce, moment...  \n",
       "4  [nancy, la, dernière, épreuve, venait, de, bou...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenizer\n",
    "\n",
    "df['tokens_all']  = df.text_no_punctuation.apply(\n",
    "    lambda r : word_tokenize(r.lower())\n",
    ")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_no_punctuation</th>\n",
       "      <th>tokens_all</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Le chemin longe les nombreux bassins d'élevage...</td>\n",
       "      <td>Le chemin longe les nombreux bassins d élevage...</td>\n",
       "      <td>[le, chemin, longe, les, nombreux, bassins, d,...</td>\n",
       "      <td>[chemin, longe, nombreux, bassins, élevage, am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Le secours et le salut des âmes pour les habit...</td>\n",
       "      <td>Le secours et le salut des âmes pour les habit...</td>\n",
       "      <td>[le, secours, et, le, salut, des, âmes, pour, ...</td>\n",
       "      <td>[secours, salut, âmes, habitants, marquisat, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>L'association « Le Haut Fer » organise deux ma...</td>\n",
       "      <td>L association   Le Haut Fer   organise deux ma...</td>\n",
       "      <td>[l, association, le, haut, fer, organise, deux...</td>\n",
       "      <td>[association, haut, fer, organise, deux, manif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>On les trouve très actifs en ce moment les jeu...</td>\n",
       "      <td>On les trouve très actifs en ce moment les jeu...</td>\n",
       "      <td>[on, les, trouve, très, actifs, en, ce, moment...</td>\n",
       "      <td>[trouve, très, actifs, moment, jeunes, agricul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NANCY. - La dernière épreuve venait de boucler...</td>\n",
       "      <td>NANCY    La dernière épreuve venait de boucler...</td>\n",
       "      <td>[nancy, la, dernière, épreuve, venait, de, bou...</td>\n",
       "      <td>[nancy, dernière, épreuve, venait, boucler, st...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Le chemin longe les nombreux bassins d'élevage...   \n",
       "1  Le secours et le salut des âmes pour les habit...   \n",
       "2  L'association « Le Haut Fer » organise deux ma...   \n",
       "3  On les trouve très actifs en ce moment les jeu...   \n",
       "4  NANCY. - La dernière épreuve venait de boucler...   \n",
       "\n",
       "                                 text_no_punctuation  \\\n",
       "0  Le chemin longe les nombreux bassins d élevage...   \n",
       "1  Le secours et le salut des âmes pour les habit...   \n",
       "2  L association   Le Haut Fer   organise deux ma...   \n",
       "3  On les trouve très actifs en ce moment les jeu...   \n",
       "4  NANCY    La dernière épreuve venait de boucler...   \n",
       "\n",
       "                                          tokens_all  \\\n",
       "0  [le, chemin, longe, les, nombreux, bassins, d,...   \n",
       "1  [le, secours, et, le, salut, des, âmes, pour, ...   \n",
       "2  [l, association, le, haut, fer, organise, deux...   \n",
       "3  [on, les, trouve, très, actifs, en, ce, moment...   \n",
       "4  [nancy, la, dernière, épreuve, venait, de, bou...   \n",
       "\n",
       "                                              tokens  \n",
       "0  [chemin, longe, nombreux, bassins, élevage, am...  \n",
       "1  [secours, salut, âmes, habitants, marquisat, b...  \n",
       "2  [association, haut, fer, organise, deux, manif...  \n",
       "3  [trouve, très, actifs, moment, jeunes, agricul...  \n",
       "4  [nancy, dernière, épreuve, venait, boucler, st...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove stopwords\n",
    "\n",
    "def remove_stopword(tokens):\n",
    "     return [w for w in tokens if (w not in list_stopwords) ]\n",
    "\n",
    "# Verifier que ca marche\n",
    "remove_stopword(tokens)\n",
    "\n",
    "# appliquer a la dataframe\n",
    "\n",
    "df['tokens'] = df.tokens_all.apply(\n",
    "    lambda tks : remove_stopword(tks) \n",
    ")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['text', 'text_no_punctuation', 'tokens_all', 'tokens'], dtype='object')\n",
      "Index(['text', 'tokens'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# enlever les colonnes intermediaires\n",
    "\n",
    "print(df.columns)\n",
    "\n",
    "df = df[['text', 'tokens']]\n",
    "\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  \\\n",
      "0  Le chemin longe les nombreux bassins d'élevage...   \n",
      "1  Le secours et le salut des âmes pour les habit...   \n",
      "2  L'association « Le Haut Fer » organise deux ma...   \n",
      "3  On les trouve très actifs en ce moment les jeu...   \n",
      "4  NANCY. - La dernière épreuve venait de boucler...   \n",
      "\n",
      "                                              tokens  token_count  \n",
      "0  [chemin, longe, nombreux, bassins, élevage, am...          103  \n",
      "1  [secours, salut, âmes, habitants, marquisat, b...           62  \n",
      "2  [association, haut, fer, organise, deux, manif...           59  \n",
      "3  [trouve, très, actifs, moment, jeunes, agricul...           60  \n",
      "4  [nancy, dernière, épreuve, venait, boucler, st...           60  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    15120.000000\n",
       "mean        80.555225\n",
       "std         35.676722\n",
       "min         44.000000\n",
       "25%         64.000000\n",
       "50%         72.000000\n",
       "75%         86.000000\n",
       "max       1011.000000\n",
       "Name: token_count, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nombre de tokens par rangée\n",
    "pd.options.mode.chained_assignment = None\n",
    "df['token_count'] = df.tokens.apply( lambda r : len(r) )\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "# repartition du nombre de tokens\n",
    "df.token_count.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ \"161. Brisset (CSA BA 133) ; 162. Tascone ; 163. Leroy (SNCF) ; 164. Cassin (Tomblaine) ; 165. Aubert (Frouard) ; 166. Pascaot ; 167. Lagrange (Messein) ; 168. Vermandé (Messein) ; 169. Rouyer (Commercy) ; 170. Chrisment (Nancy) ; 171. Lepeltier (Ecrouves) ; 172. Jacquot ; 173. Delery ; 174. Billy ; 175. Lamy ; 176. Charpentier (Ludres) ; 177. Tousch (Gondrecourt) ; 178. Carbillet (La Poste) ; 179. Brunot (Philips) ; 180. Benyoussef ; 181. Starosse (Allamps) ; 182. Seiler (Vandoeuvre) ; 183.Discristofano ; 184. Fossard (Vandoeuvre) ; 185. Boyer ; 186. Leroy ; 187. Carreiras (Golbey) ; 188. Evrard ; 189. Vagne (CSA BA 133) ; 190. Georges (Tomblaine) ; 191. Aubert (Maidières) ; 192. Leroux ; 193. Geoffroy ; 194. Clausse (Chaudenay) ; 195. Deuze (Villers) ; 196. P. Knapek (Ecrouves) ; 197. F. Kanpek (Toul) ; 198. Noël ; 199. Maire (Varangéville) ; 200. Mercky ; 201. Gaumer ; 202. Vincent (Sommerviller) ; 203. Socha (Aingeray) ; 204. Boulot (Blénod) ; 205. Houin (Amicale CHU) ; 206. Borgniet (Jarville) ; 207. Cazzulani (Bulligny) ; 208. Parisot (Lenoncourt) ; 209. Baron (Gondreville) ; 210. Marchal . 211. Ingret (Essey-lès-Nancy) ; 212. Leonardi (Saizerais) ; 213. Bar (St-Max) ; 214. Labarbe (Nancy) ; 215. Picart (Villers) ; 216. Pageot (Essey-lès-Nancy) ; 217. Guillou (Art-sur-Meurthe) ; 218. Bourgeois (Gondrecourt) ; 219. Sutter (Maxéville) ; 220. Marchi (Vandoeuvre) ; 221. Gonthier ; 222. Girardi ; 223. Heckel (Maxéville) ; 224. Lee (Philips) ; 225. Compagnon (Richardménil) ; 226. Obeltz (Gars Val Cross) ; 227. Othelet (Tantonville) ; 228. Kovac (Pexonne) ; 229. T. Godfroy ; 230. Barin . 231. Payeur (Chaudenay) ; 232. Baraud (Thierville) ; 233. Pochit ; 234. Antoine ; 235. Peiffer (Chaudenay) ; 236. R. Deloy (Nomexy) ; 237. G. Deloy ; 238. Milbach ; 239. Andre (Benney) ; 240. Petitjean ; 241. Perrin (Lunéville) ; 242. Pernel (Blénod) ; 243. Ferreira ; 244. Alfieri (Laneuveville) ; 245. Hutinet ; 246. Defente (Blénod) ; 247. Villaume ; 248. Gérard (Nves-Maisons) ; 249. Payeur (Commercy) ; 250. Bournon ; 251. Collet (Philips) ; 252. Ludmann (Hériménil) ; 253. Vallance (Goviller) ; 254. Belin (Vandoeuvre) ; 255. Verd ; 256. Renard . 257. Bastien ; 258. Hincelin ; 259. Roger (Essey-lès-Nancy) ; 260. Rakotoarison (St-Max) ; 261. Deshayes (CSA BA 133) ; 262. Debias ; 263. Mouillé (Tomblaine) ; 264. Remy (Nancy) ; 265. Baechler (Dombasle) ; 266. Maillet ; 267. Saint Jours ; 268. Pierre (Blénod) ; 269. Morisot . 270. Serveur (Essey-lès-Nancy) ; 271. Fritz ; 272. Mangenot ; 273. Butin (Toul) ; 274. J. Etienne ; 275. D. Etienne ; 276. Mathis ; 277. Boyer (Gondrecourt) ; 278. Mandra (Gars Val Cross) ; 279. Belhote (Pulnoy) ; 280. Alison (Nimes) ; 281. Liegey (Varangéville) ; 282. Pierrat (Spiridon Club) ; 283. Humbert (Seichamps) ; 284. Back (Bouzonville) ; 285. Dewitte ; 286. Philippe (Thiébauménil) ; 287. Boyer ; 288. Durand (Houdemont) ; 289. Thieblemont ; 290. Baumann (Boncourt) ; 291. Tabouret (Toul) ; 292. Husson (Blénod) ; 293. Emmanuel (Damelevieres) ; 294. Pernot ; 295. Schwoerer (Nancy) ; 296. Sitz (Dieulouard) ; 297. Chuste ; 298. Laithier (Nancy) ; 299. Abscheidt ; 300. Pagliarela (Philips) ; 301. Tardy (Golbey) ; 302. Koffolt (Vincey) ; 303. Chassatte (Dombasle) ; 304. Vaxelaire ; 305. Robert (Nancy) ; 306. Chretien (Villers) ; 307. Paulin (Belleville) ; 308. Morville (Villers) ; 309. Ziegler (Bataville) ; 310. Morville (Gondrecourt) ; 311. Nowakowski (SNCF) ; 312. Fourar (Vandoeuvre) ; 313. Osiewiez (Energ.Pavois) ; 314. Dominiak (Vandoeuvre) ; 315. Ricatte (Lunéville) ; 316. Faltot (Lunéville) ; 317. Candat ; 318. Bardot (Lunéville) ; 319. Martin . 320. Ferry ; 321. Mathieu (Nancy) ; 322. Chenin ; 323. Geoffroy (AFPA) ; 324. Filliot (AFPA) ; 325. Grapinet ; 326. Pelon (Laquenexy) ; 327. Tournoy (Laneuveville) ; 328. Picazo ; 329. Poirot (Velaine-en-Haye) ; 330. Lostetier ; 331. Zamboni (Varangéville) ; 332. Denat ; 333. Charpentier (Ludres) ; 334. Michel ; 335. Dolveck (Blénod) ; 336. Buchi ; 337. Berteaux ; 338. Legast (Chaudenay) ; 339. Pawlowski (Dieulouard) ; 340. Reinhard (Langley) ; 341. Moine (Heillecourt) ; 342. Carpentier (SNCF) ; 343. Liegeois (Ars-sur-Moselle) ; 344. Gousse (Villers) ; 345. Poinsard (Lunéville) ; 346. Dimarcq ; 347. Blaise (Blénod) ; 348. Desgranges (Gondreville) ; 349. Falchetto ; 350. Flament (Méréville) ; 351. Heloir (Messein) ; 352. Arson (Gars Val Cross) ; 353. Richard (Einvaux) ; 354. Mercier (Rosières-aux-Salines) ; 355. Pernossi (Alstom Moteurs) ; 356. Poncet (Vincey) ; 357. Wolfarth (Malleloy) ; 358. Toldre (Laneuveville) ; 359. Touillet (Nancy) ; 360. Brice (Spiridon Club) ; 361. Seyer (Metz) ; 362. Mauclair (Lunéville) ; 363. Bourtembourg (Saulxures-lès-Nancy) ; 364. Gallois ; 365. Leroy (Blénod) ; 366. Schneider (Pagny-sur-Moselle) ; 367. Pierre (Mont-sur-Meurthe) ; 368. Vachon . 369. Lorphelin (Laneuville) ; 370. Thil ; 371. Lafont (Nancy) ; 372. Lunéville) ; 373. Martinez (La Poste) ; 374. Drahon (Toul) ; 375. Cuny (Gars Val Cross) ; 376. Rousseau (Malzéville) ; 377. Vernay (PAM) ; 378. Borgniet (Jarville) ; 379. Caballero (Ecrouves) ; 380. Hacquard (Champigneulles) ; 381. Remy (Neuves-Maisons) ; 382. Ingret (Essey-lès-Nancy) ; 383. Liegeois (Ars-sur-Moselle) ; 384. Thivet . 385. Deutzer (Philips) ; 386. Zminka (Toul) ; 387. François (Energ.Pavois) ; 388. Charrue (Paris) ; 389. Mercier (Bouxières) ; 390. Leclere ; 391. Bourguignon (Blainville) ; 392. Durand (Gars Val Cross) ; 393. Maron (Custines) ; 394. Huttier ; 395. Hesse (Bicquelet) ; 396. Moine (Heillecourt) ; 397. Boul ; 398. Evezard ; 399. Charpentier (Ludres) ; 400. Melich ; 401. Allard ; 402. Richard ; 403. Steck (Lucey) ; 404. Flament (Richardménil) ; 405. Genot (Heillecourt) ; 406. Mougel (Ludres) ; 407. Richard (Sports Loisirs) ; 408. Baillot ; 409. S. Bour (Heillecourt) ; 410. A. Bour (Heillecourt) ; 411. Lance ; 412. Melchior (Laxou) ; 413. Haut (Metz) ; 414. Bruant (Tomblaine) ; 415. Barbette ; 416. Chassatte (Dombasle) ; 417. Joublin ; 418. Liegey (Varangéville) ; 419. Marchal ; 420. Henard ; 421. Mouchet (Sport Loisirs) ; 422. Stephan (Pulnoy) ; 423. Gauchey (Dommartin-lès-Toul) ; 424. Geoffroy ; 425. Gallois (Maxéville) ; 426. Chapelle (Golbey) ; 427. Serveur (Essey-lès-Ncy) ; 428. Piazuelo (Toul) ; 429. Arson (Gars Val Cross) ; 430. Sitz (Dieulouard) ; 431. Poinsignon (Seichamps) ; 432. Thirion ; 433. Larbaletrier (Malzéville) ; 434. Desloges (Blénod) ; 435. Pelte (Réméréville) ; 436. Simon ; 437. Keniche (Nancy) ; 438. Othelet ; 439. Marchal ; 440. Belin (Vandoeuvre) ; 441. Carpentier (SNCF) ; 442. Heloir (Messein) ; 443. Borgniet (Laneuveville) ; 444. L'Huillier ; 445. Boes (Menaucourt) ; 446. Morlon (Jarville) ; 447. Dieudonne (Varangéville) ; 448. Prignot (Villers-lès-Ncy) ; 449. Ihry (Neuves-Maisons) ; 450. Lottin (Laferte-sur-Am.) ; 451. Lotto ; 452. Durand (Gars Val Cross) ; 453. C. Larbaletrier (CHU Nancy) ; 454. Mathis (Rosières-aux-Salines) ; 455. Schatzbe ; 456. Dannequin ; 457. Cael ; 458. Genelot ; 459. Rahnena (Ludres) ; 460. Montovani ; 461. Philippot ; 462. Schertz ; 463. Barozzi (Nancy) ; 464. Simon (Seichamps) ; 465. Heinrich ; 466. Deny (Neuves-Maisons) ; 467. Varnerot (Dommartin-lès-Toul) ; 468. Deveze ; 469. Bicquelet ; 470. Haut (Metz) ; 471. Rouyer (AFPA) ; 472. Pierot (Sport Loisir) ; 473. Legroux (AFPA) ; 474. Voitot (Toul) ; 475. Fourcaulx (Fléville) ; 476. Dubail (Neugartheim) ; 477. G. Dannequin ; 478. D. Bicquelet ; 479. Martin ; 480. Durand (Gars Val Cross) ; 481. Tekieli (Rosières-aux-Salines) ; 482. Marc (Ars-sur-Moselle) ; 483. Thivet ; 484. Gauchey (Dommartin-lès-Toul) ; 485. Genelot ; 486. Picot (Jarville) ; 487. Moriset.\"]\n"
     ]
    }
   ],
   "source": [
    "# quel document a 955 tokens?\n",
    "\n",
    "condition = (df.token_count == 955)\n",
    "print(df[condition].text.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([5457], dtype='int64')\n",
      "(15115, 3)\n"
     ]
    }
   ],
   "source": [
    "# quel index\n",
    "print(df[condition].index)\n",
    "\n",
    "# \n",
    "condition = (df.token_count < 800)\n",
    "print(df[condition].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15118, 3)\n",
      "(15118, 3)\n",
      "count    15118.000000\n",
      "mean        80.435838\n",
      "std         34.134027\n",
      "min         44.000000\n",
      "25%         64.000000\n",
      "50%         72.000000\n",
      "75%         86.000000\n",
      "max        949.000000\n",
      "Name: token_count, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexis/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:7: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "# enlever le paragraphe le plus long\n",
    "\n",
    "condition_filtrage = df.token_count < 955\n",
    "print(df[condition_filtrage].shape)\n",
    "\n",
    "df = df[condition_filtrage]\n",
    "print(df[condition_filtrage].shape)\n",
    "\n",
    "print(df.token_count.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(82416 unique tokens: ['chemin', 'longe', 'nombreux', 'bassins', 'élevage']...)\n"
     ]
    }
   ],
   "source": [
    "# Gensim - Vocabulaire\n",
    "\n",
    "from gensim import corpora, models\n",
    "dictionary  = corpora.Dictionary(df.tokens)\n",
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ \"Le chemin longe les nombreux bassins d'élevage. Les amateurs de poissons d'eau douce pourront y faire un détour et ramener à la maison, moyennant finance, quelques belles truites arc-en-ciel. Le chemin suit le ruisseau jusqu'à un vaste parking équipé pour le pique-nique avec un chalet confortable, demander la clé à la mairie. Depuis le parking, suivre le chemin de débardage qui prend rapidement de l'altitude, passe devant un réservoir et rencontre un chemin de crête. Celui-ci, par la droite, sort du bois, dessert la maison des Poteys et se maintient sur les collines dominant Xertigny. Laisser un premier chemin à gauche puis deux autres à droite pour traverser la route de Plombières. Emprunter la route sur 100 m à droite et s'engager dans le petit chemin de terre qui longe le bois du Fays Richard et conduit à Sainte-Valburge. Regagner le centre du village. L'ancien château de la brasserie qui abrite les services municipaux est entouré d'un arboretum. Vous pourrez y découvrir un spécimen exceptionnel de séquoia.\"\n",
      "  list([(0, 6), (1, 2), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 2), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 2), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 1), (35, 1), (36, 1), (37, 1), (38, 1), (39, 1), (40, 1), (41, 1), (42, 1), (43, 1), (44, 1), (45, 1), (46, 1), (47, 3), (48, 1), (49, 2), (50, 1), (51, 1), (52, 1), (53, 1), (54, 1), (55, 1), (56, 1), (57, 1), (58, 1), (59, 1), (60, 1), (61, 1), (62, 1), (63, 2), (64, 1), (65, 1), (66, 1), (67, 1), (68, 1), (69, 1), (70, 1), (71, 1), (72, 1), (73, 1), (74, 1), (75, 1), (76, 1), (77, 1), (78, 1), (79, 1), (80, 1), (81, 1), (82, 1), (83, 1), (84, 1), (85, 1), (86, 1), (87, 1), (88, 1), (89, 1), (90, 1)])]\n",
      " [ \"Le secours et le salut des âmes pour les habitants du marquisat de Bulgnéville et les lieux circonvoisins étant un besoin et grâce au comte de Rorté, marquis de Pont-à-Mousson, entre autres, ce sont les pères Récollets de la custodie de Saint-Nicolas qui s'établirent. Après leur installation sur les lieux, les pères demandèrent l'autorisation de bâtir un monastère. Par une lettre patente du 28 janvier 1709, le duc Léopold donnait cette autorisation aux deux premiers pères des Récollets. Le duc autorisait la présence de neufs pères et trois frères, afin de pouvoir rendre au peuple, les services convenables à la plus grande gloire de Dieu.\"\n",
      "  list([(60, 1), (61, 1), (82, 1), (91, 1), (92, 1), (93, 1), (94, 1), (95, 1), (96, 1), (97, 2), (98, 1), (99, 1), (100, 1), (101, 1), (102, 1), (103, 1), (104, 1), (105, 1), (106, 1), (107, 4), (108, 2), (109, 1), (110, 1), (111, 1), (112, 1), (113, 1), (114, 1), (115, 1), (116, 2), (117, 1), (118, 1), (119, 1), (120, 1), (121, 1), (122, 1), (123, 1), (124, 2), (125, 1), (126, 1), (127, 1), (128, 1), (129, 1), (130, 1), (131, 1), (132, 1), (133, 1), (134, 1), (135, 1), (136, 1), (137, 1), (138, 1), (139, 1), (140, 1), (141, 1), (142, 1)])]\n",
      " [ \"L'association « Le Haut Fer » organise deux manifestations à l'occasion des journées nationales du patrimoine. A Denipaire, découverte du village. Ce week-end sera l'occasion de s'intéresser à l'architecture rurale, à son évolution et à sa sauvegarde. La manifestation se déroulera en deux temps : samedi 18 septembre à 20 h, à la salle des fêtes, soirée causerie et projection de diapositives sur l'histoire de l'habitat rural de Denipaire et sur l'évolution de l'architecture et de la décoration des fermes au cours des siècles ; dimanche 19 septembre, à 14 h 30, visite commentée du village, départ près de la mairie.\"\n",
      "  list([(33, 1), (60, 2), (77, 2), (143, 1), (144, 1), (145, 1), (146, 1), (147, 1), (148, 2), (149, 1), (150, 1), (151, 1), (152, 1), (153, 2), (154, 1), (155, 1), (156, 1), (157, 1), (158, 2), (159, 1), (160, 2), (161, 1), (162, 1), (163, 1), (164, 1), (165, 1), (166, 1), (167, 2), (168, 1), (169, 2), (170, 1), (171, 1), (172, 1), (173, 1), (174, 1), (175, 1), (176, 1), (177, 1), (178, 1), (179, 1), (180, 1), (181, 1), (182, 1), (183, 1), (184, 1), (185, 1), (186, 1), (187, 1), (188, 1), (189, 1), (190, 1)])]\n",
      " [ \"On les trouve très actifs en ce moment les jeunes agriculteurs du canton L'Islois. En effet après le succès de l'opération sourire du mois d'août, voilà qu'ils ont récidivé en organisant dimanche dans les champs de la plaine de Mancenans, au lieu dit la Tuilerie, un concours de labour. Depuis la route qui mène à Soye, les automobilistes pouvaient apercevoir une quinzaine d'engins agricoles, derrière lesquels était attelée une charrue, occupée à travailler la terre. Onze jeunes agriculteurs s'étaient inscrits au concours tandis que les épouses et les copines étaient mobilisées sous le chapiteau pour servir des boissons et des casses-croûtes.\"\n",
      "  list([(34, 1), (63, 1), (69, 1), (113, 1), (183, 1), (191, 1), (192, 1), (193, 1), (194, 1), (195, 2), (196, 2), (197, 1), (198, 1), (199, 1), (200, 1), (201, 1), (202, 1), (203, 1), (204, 1), (205, 1), (206, 1), (207, 1), (208, 1), (209, 1), (210, 1), (211, 1), (212, 1), (213, 1), (214, 1), (215, 2), (216, 1), (217, 1), (218, 1), (219, 1), (220, 1), (221, 1), (222, 1), (223, 1), (224, 1), (225, 1), (226, 1), (227, 1), (228, 1), (229, 1), (230, 1), (231, 1), (232, 1), (233, 1), (234, 1), (235, 1), (236, 1), (237, 1), (238, 1), (239, 1), (240, 1), (241, 1), (242, 1)])]\n",
      " [ \"NANCY. - La dernière épreuve venait de boucler le Stanislas 99. Le visage tendu, Pascal Thiébaut en avait fini d'encourager frénétiquement (« Relâche-toi ») Bob Tahri, son poulain qui venait d'échouer contre le record de France Espoirs du 3.000 m, par des grands . Le spectacle était ailleurs... Des tribunes, dévalèrent des grappes de spectateurs qui coururent, attirées par des aimants, espèces sonnantes et non trébuchantes, vers les kas (tambours guadeloupéens) du groupe « Joupa Karayïb » « On est venu donner un coup de main », expliqua Pierre Henriol, un musicien, « car le sport est fait de rythme et de tempo ».\"\n",
      "  list([(243, 1), (244, 1), (245, 1), (246, 2), (247, 1), (248, 1), (249, 1), (250, 1), (251, 1), (252, 1), (253, 1), (254, 1), (255, 1), (256, 1), (257, 1), (258, 1), (259, 1), (260, 1), (261, 1), (262, 1), (263, 1), (264, 1), (265, 1), (266, 1), (267, 1), (268, 1), (269, 1), (270, 1), (271, 1), (272, 1), (273, 1), (274, 1), (275, 1), (276, 1), (277, 1), (278, 1), (279, 1), (280, 1), (281, 1), (282, 1), (283, 1), (284, 1), (285, 1), (286, 1), (287, 1), (288, 1), (289, 1), (290, 1), (291, 1), (292, 1), (293, 1), (294, 1), (295, 1), (296, 1), (297, 1), (298, 1), (299, 1), (300, 1), (301, 1)])]]\n"
     ]
    }
   ],
   "source": [
    "# corpus_gensim\n",
    "\n",
    "df['corpus_gensim'] = df.tokens.apply(lambda d : dictionary.doc2bow(d))\n",
    "\n",
    "print(df[['text','corpus_gensim']] .head().values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_gensim = [c for c in df.corpus_gensim ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== topic #0\n",
      "0.022: a,  0.008: plus,  0.007: cette,  0.005: deux,  0.004: être,  0.004: tout,  0.004: faire,  0.004: président,  0.004: fait,  0.003: bien\n",
      "\n",
      "=== topic #1\n",
      "0.014: a,  0.011: enfants,  0.008: cette,  0.007: ils,  0.007: plus,  0.006: école,  0.006: élèves,  0.005: année,  0.005: jeunes,  0.005: tous\n",
      "\n",
      "=== topic #2\n",
      "0.037: a,  0.008: plus,  0.008: fait,  0.007: tout,  0.007: bien,  0.006: comme,  0.006: ils,  0.006: ans,  0.005: deux,  0.005: très\n",
      "\n",
      "=== topic #3\n",
      "0.009: a,  0.004: deux,  0.004: plus,  0.003: mètres,  0.003: circulation,  0.003: véhicule,  0.003: poids,  0.003: parking,  0.003: voiture,  0.002: hauteur\n",
      "\n",
      "=== topic #4\n",
      "0.012: a,  0.009: plus,  0.007: eau,  0.005: ils,  0.004: bois,  0.004: tout,  0.003: comme,  0.003: cette,  0.003: après,  0.003: faire\n",
      "\n",
      "=== topic #5\n",
      "0.040: f,  0.021: 000,  0.009: conseil,  0.008: a,  0.007: 1,  0.006: 500,  0.006: travaux,  0.005: francs,  0.005: millions,  0.004: 2\n",
      "\n",
      "=== topic #6\n",
      "0.038: 6,  0.023: 5,  0.021: 2,  0.020: 4,  0.019: 0,  0.018: 1,  0.015: 3,  0.012: bat,  0.011: a,  0.009: 7\n",
      "\n",
      "=== topic #7\n",
      "0.008: a,  0.003: plus,  0.002: fleurs,  0.002: fer,  0.002: cora,  0.002: cette,  0.002: amérique,  0.002: deux,  0.002: plantes,  0.002: haut\n",
      "\n",
      "=== topic #8\n",
      "0.007: jeu,  0.007: match,  0.007: a,  0.006: but,  0.005: coup,  0.005: tir,  0.005: plus,  0.004: joueurs,  0.004: minutes,  0.004: ballon\n",
      "\n",
      "=== topic #9\n",
      "0.029: rue,  0.009: ans,  0.007: saint,  0.007: enfants,  0.007: a,  0.006: où,  0.005: puis,  0.004: famille,  0.004: église,  0.004: jean\n",
      "\n",
      "=== topic #10\n",
      "0.007: a,  0.002: fra,  0.002: western,  0.002: ita,  0.002: plus,  0.002: lions,  0.002: contemporain,  0.001: groupe,  0.001: blues,  0.001: mk\n",
      "\n",
      "=== topic #11\n",
      "0.016: a,  0.008: club,  0.007: équipe,  0.006: plus,  0.006: ans,  0.005: tout,  0.005: saison,  0.003: cette,  0.003: france,  0.003: joueurs\n",
      "\n",
      "=== topic #12\n",
      "0.021: a,  0.005: hier,  0.005: tribunal,  0.005: plus,  0.004: ans,  0.003: prison,  0.003: deux,  0.003: france,  0.002: dernier,  0.002: juge\n",
      "\n",
      "=== topic #13\n",
      "0.011: a,  0.007: championnat,  0.006: course,  0.006: deux,  0.006: équipe,  0.006: france,  0.005: première,  0.005: contre,  0.005: équipes,  0.005: trois\n",
      "\n",
      "=== topic #14\n",
      "0.011: marie,  0.010: jean,  0.008: nicolas,  0.007: pierre,  0.006: julien,  0.006: ans,  0.005: aurélie,  0.005: céline,  0.005: anne,  0.004: sébastien\n",
      "\n",
      "=== topic #15\n",
      "0.016: plus,  0.011: a,  0.007: tout,  0.006: encore,  0.005: comme,  0.005: ils,  0.004: bien,  0.004: faire,  0.004: cette,  0.003: ça\n",
      "\n",
      "=== topic #16\n",
      "0.018: 1,  0.013: p,  0.012: 2,  0.009: b,  0.009: a,  0.009: 3,  0.008: 4,  0.007: 12,  0.007: f,  0.007: 5\n",
      "\n",
      "=== topic #17\n",
      "0.009: dimanche,  0.007: km,  0.006: a,  0.006: fête,  0.006: cette,  0.005: après,  0.005: h,  0.005: club,  0.005: midi,  0.005: samedi\n",
      "\n",
      "=== topic #18\n",
      "0.133: h,  0.041: 30,  0.017: 14,  0.016: 15,  0.016: 18,  0.014: 20,  0.013: ind,  0.012: 17,  0.012: 19,  0.012: 12\n",
      "\n",
      "=== topic #19\n",
      "0.008: a,  0.003: france,  0.003: sédrati,  0.003: rpr,  0.002: rc,  0.002: plus,  0.002: deux,  0.002: président,  0.002: droite,  0.002: aude\n"
     ]
    }
   ],
   "source": [
    "num_topics= 20\n",
    "\n",
    "# Le model LDA\n",
    "lda = models.LdaModel(corpus_gensim,\n",
    "    id2word      = dictionary,\n",
    "    num_topics   = num_topics,\n",
    "    alpha        = 'asymmetric',\n",
    "    eta          = 'auto',\n",
    "    passes       = 2,\n",
    "    iterations   = 20\n",
    ")\n",
    "\n",
    "for t in lda.show_topics(num_topics=num_topics, formatted=True, log = False):\n",
    "    print(\"\\n=== topic #{}\".format(t[0]))\n",
    "    print(t[1].replace('*', ': ').replace(' +',', ').replace('\"',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
