{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 2+5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "DATA_PATH = '../data/'\n",
    "filename  = 'estrepublicain_annee_1999.csv' \n",
    "\n",
    "df = pd.read_csv(DATA_PATH + filename) #lire le fichier à partir de là où il est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "= dimensions\n",
      "(1000, 1)\n",
      "= 5 premieres rangés\n",
      "                                                text\n",
      "0  André Bauer, le Bonhomme de St-Dié ; Alain Dag...\n",
      "1  Le Smash Entente Club de Lunéville (SECL) a re...\n",
      "2  En tout cas, du côté du PS Dole qui reste en c...\n",
      "3  « Le nombre des donneurs était en légère baiss...\n",
      "4  ELOYES._ Les Ramoncenais n'auront tenu qu'une ...\n",
      "= Noms des colonnes\n",
      "Index(['text'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#df\n",
    "#df.shape \n",
    "#df.head()\n",
    "#df.columns \n",
    "\n",
    "df\n",
    "print(\"= dimensions\") \n",
    "print(df.shape) #compte les lignes et la colonne  ****** les dimensions rangés / lignes, colonne\n",
    "print(\"= 5 premieres rangés\")\n",
    "print(df.head())  #affiche le paragraph      ********     5 premiers rangés \n",
    "print(\"= Noms des colonnes\")\n",
    "print(df.columns) # ******                               Noms des colonnes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ne garder que les 100 premiers commentaires\n",
    "df=df[0:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['les', 'médiateurs', 'confirment', '«', \"l'absence\", 'de', 'solution', 'parfaite', '»', '.']\n",
      "['les', 'médiateurs', 'confirment', '«', \"l'absence\", 'de', 'solution', 'parfaite', '».', '']\n"
     ]
    }
   ],
   "source": [
    "#tokenisation PARTIE 1\n",
    "from nltk import word_tokenize\n",
    "\n",
    "sentence = \"les médiateurs confirment « l'absence de solution parfaite ». \"\n",
    "\n",
    "tokens = word_tokenize(sentence)\n",
    "print(tokens)\n",
    "\n",
    "tokens_on_space = sentence.split(' ')\n",
    "print(tokens_on_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liste original de signe de ponctuations\n",
      "\t!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n",
      "Liste étendue de signe de ponctuations\n",
      "\t!\"#$%&'()*+,./:;<=>?@[\\]^`{|}~“”…»«’\r\n",
      "\n",
      "{'!': ' ', '\"': ' ', '#': ' ', '$': ' ', '%': ' ', '&': ' ', \"'\": ' ', '(': ' ', ')': ' ', '*': ' ', '+': ' ', ',': ' ', '.': ' ', '/': ' ', ':': ' ', ';': ' ', '<': ' ', '=': ' ', '>': ' ', '?': ' ', '@': ' ', '[': ' ', '\\\\': ' ', ']': ' ', '^': ' ', '`': ' ', '{': ' ', '|': ' ', '}': ' ', '~': ' ', '“': ' ', '”': ' ', '…': ' ', '»': ' ', '«': ' ', '’': ' ', '\\r': ' ', '\\n': ' '}\n",
      "les médiateurs confirment « l'absence de solution parfaite ». \n",
      "les médiateurs confirment   l absence de solution parfaite    \n"
     ]
    }
   ],
   "source": [
    "#ponctuation  PARTIE 2\n",
    "import string\n",
    "\n",
    "print(\"Liste original de signe de ponctuations\")\n",
    "print(\"\\t{}\".format(string.punctuation))\n",
    "\n",
    "\n",
    "sentence = \"les médiateurs confirment « l'absence de solution parfaite ». \"\n",
    "\n",
    "punctuation_chars = ''.join([s for s in string.punctuation if s not in ['_', '-']  ]) + '“”…»«’\\r\\n'\n",
    "print(\"Liste étendue de signe de ponctuations\")\n",
    "print(\"\\t{}\".format(punctuation_chars))\n",
    "\n",
    "\n",
    "#  Construction d'un dict { '~':' ', '$': ' ', ... }\n",
    "d = {}\n",
    "for k in punctuation_chars:\n",
    "    d[k] = ' '\n",
    "    \n",
    "print(d)\n",
    "\n",
    "# L'operateur de translation\n",
    "translator = str.maketrans(d)  #une fois qu'on a le dictionnaire\n",
    "\n",
    "new_sentence = sentence.translate(translator)\n",
    "print(sentence)\n",
    "print(new_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['les', 'médiateurs', 'confirment', 'l', 'absence', 'de', 'solution', 'parfaite']\n",
      "=== stopwords - français:\n",
      "['au', 'aux', 'avec', 'ce', 'ces', 'dans', 'de', 'des', 'du', 'elle', 'en', 'et', 'eux', 'il', 'je', 'la', 'le', 'leur', 'lui', 'ma', 'mais', 'me', 'même', 'mes', 'moi', 'mon', 'ne', 'nos', 'notre', 'nous', 'on', 'ou', 'par', 'pas', 'pour', 'qu', 'que', 'qui', 'sa', 'se', 'ses', 'son', 'sur', 'ta', 'te', 'tes', 'toi', 'ton', 'tu', 'un', 'une', 'vos', 'votre', 'vous', 'c', 'd', 'j', 'l', 'à', 'm', 'n', 's', 't', 'y', 'été', 'étée', 'étées', 'étés', 'étant', 'étante', 'étants', 'étantes', 'suis', 'es', 'est', 'sommes', 'êtes', 'sont', 'serai', 'seras', 'sera', 'serons', 'serez', 'seront', 'serais', 'serait', 'serions', 'seriez', 'seraient', 'étais', 'était', 'étions', 'étiez', 'étaient', 'fus', 'fut', 'fûmes', 'fûtes', 'furent', 'sois', 'soit', 'soyons', 'soyez', 'soient', 'fusse', 'fusses', 'fût', 'fussions', 'fussiez', 'fussent', 'ayant', 'ayante', 'ayantes', 'ayants', 'eu', 'eue', 'eues', 'eus', 'ai', 'as', 'avons', 'avez', 'ont', 'aurai', 'auras', 'aura', 'aurons', 'aurez', 'auront', 'aurais', 'aurait', 'aurions', 'auriez', 'auraient', 'avais', 'avait', 'avions', 'aviez', 'avaient', 'eut', 'eûmes', 'eûtes', 'eurent', 'aie', 'aies', 'ait', 'ayons', 'ayez', 'aient', 'eusse', 'eusses', 'eût', 'eussions', 'eussiez', 'eussent']\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'list_stopwords' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-92d3a54a8026>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mtokens_sans_stopwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist_stopwords\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mtokens_sans_stopwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'list_stopwords' is not defined"
     ]
    }
   ],
   "source": [
    "# stopwords (MAMY)\n",
    "tokens = word_tokenize(new_sentence) #ce qu'on a fait avant dans partie 1 tokenisation\n",
    "print(tokens)\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "print(\"=== stopwords - français:\")\n",
    "print(stopwords.words('french'))  #pour avoir les stopwords français\n",
    "\n",
    "stopwords = stopwords.words('french') + ['les','de'] \n",
    "\n",
    "#Equivalent: \n",
    "#stopwords = stopwords.words('french')\n",
    "#stopwords.append('les')\n",
    "#stopwords.append('de')\n",
    "\n",
    "tokens_sans_stopwords = [w for w in tokens if (w not in list_stopwords)]\n",
    "\n",
    "## Equivalent \n",
    "tokens_sans_stopwords = []\n",
    "for w in tokens:\n",
    "    if w not in list_stopwords:\n",
    "        tokens_sans_stopwords.append(w)\n",
    "\n",
    "print(tokens_sans_stopwords)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['les', 'médiateurs', 'confirment', 'l', 'absence', 'de', 'solution', 'parfaite']\n",
      "['médiateurs', 'confirment', 'absence', 'solution', 'parfaite']\n"
     ]
    }
   ],
   "source": [
    "## PROF # stopwords\n",
    "tokens = word_tokenize(new_sentence)\n",
    "print(tokens)\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "# print(\"=== stopwords - français:\")\n",
    "# print(sorted(stopwords.words('french')))\n",
    "\n",
    "list_stopwords = stopwords.words('french') + ['les', 'de']\n",
    "\n",
    "# # equivalent:\n",
    "# stopwords = stopwords.words('french')\n",
    "# stopwords.append('les')\n",
    "# stopwords.append('de')\n",
    "\n",
    "\n",
    "# \n",
    "tokens_sans_stopwords = [w for w in tokens if (w not in list_stopwords) ]\n",
    "\n",
    "## Equivalent \n",
    "tokens_sans_stopwords = []\n",
    "for w in tokens:\n",
    "    if w not in list_stopwords:\n",
    "        tokens_sans_stopwords.append(w)\n",
    "\n",
    "\n",
    "\n",
    "print(tokens_sans_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexis/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_no_punctuation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>André Bauer, le Bonhomme de St-Dié ; Alain Dag...</td>\n",
       "      <td>André Bauer  le Bonhomme de St-Dié   Alain Dag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Le Smash Entente Club de Lunéville (SECL) a re...</td>\n",
       "      <td>Le Smash Entente Club de Lunéville  SECL  a re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>En tout cas, du côté du PS Dole qui reste en c...</td>\n",
       "      <td>En tout cas  du côté du PS Dole qui reste en c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>« Le nombre des donneurs était en légère baiss...</td>\n",
       "      <td>Le nombre des donneurs était en légère baiss...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ELOYES._ Les Ramoncenais n'auront tenu qu'une ...</td>\n",
       "      <td>ELOYES _ Les Ramoncenais n auront tenu qu une ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  André Bauer, le Bonhomme de St-Dié ; Alain Dag...   \n",
       "1  Le Smash Entente Club de Lunéville (SECL) a re...   \n",
       "2  En tout cas, du côté du PS Dole qui reste en c...   \n",
       "3  « Le nombre des donneurs était en légère baiss...   \n",
       "4  ELOYES._ Les Ramoncenais n'auront tenu qu'une ...   \n",
       "\n",
       "                                 text_no_punctuation  \n",
       "0  André Bauer  le Bonhomme de St-Dié   Alain Dag...  \n",
       "1  Le Smash Entente Club de Lunéville  SECL  a re...  \n",
       "2  En tout cas  du côté du PS Dole qui reste en c...  \n",
       "3    Le nombre des donneurs était en légère baiss...  \n",
       "4  ELOYES _ Les Ramoncenais n auront tenu qu une ...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Enlevons la ponctuation (PARTIE 2)\n",
    "\n",
    "df['text_no_punctuation'] = df.text.apply(lambda \n",
    "    r : ( r.translate(translator) ) \n",
    ")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexis/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_no_punctuation</th>\n",
       "      <th>tokens_all</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>André Bauer, le Bonhomme de St-Dié ; Alain Dag...</td>\n",
       "      <td>André Bauer  le Bonhomme de St-Dié   Alain Dag...</td>\n",
       "      <td>[andré, bauer, le, bonhomme, de, st-dié, alain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Le Smash Entente Club de Lunéville (SECL) a re...</td>\n",
       "      <td>Le Smash Entente Club de Lunéville  SECL  a re...</td>\n",
       "      <td>[le, smash, entente, club, de, lunéville, secl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>En tout cas, du côté du PS Dole qui reste en c...</td>\n",
       "      <td>En tout cas  du côté du PS Dole qui reste en c...</td>\n",
       "      <td>[en, tout, cas, du, côté, du, ps, dole, qui, r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>« Le nombre des donneurs était en légère baiss...</td>\n",
       "      <td>Le nombre des donneurs était en légère baiss...</td>\n",
       "      <td>[le, nombre, des, donneurs, était, en, légère,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ELOYES._ Les Ramoncenais n'auront tenu qu'une ...</td>\n",
       "      <td>ELOYES _ Les Ramoncenais n auront tenu qu une ...</td>\n",
       "      <td>[eloyes, _, les, ramoncenais, n, auront, tenu,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  André Bauer, le Bonhomme de St-Dié ; Alain Dag...   \n",
       "1  Le Smash Entente Club de Lunéville (SECL) a re...   \n",
       "2  En tout cas, du côté du PS Dole qui reste en c...   \n",
       "3  « Le nombre des donneurs était en légère baiss...   \n",
       "4  ELOYES._ Les Ramoncenais n'auront tenu qu'une ...   \n",
       "\n",
       "                                 text_no_punctuation  \\\n",
       "0  André Bauer  le Bonhomme de St-Dié   Alain Dag...   \n",
       "1  Le Smash Entente Club de Lunéville  SECL  a re...   \n",
       "2  En tout cas  du côté du PS Dole qui reste en c...   \n",
       "3    Le nombre des donneurs était en légère baiss...   \n",
       "4  ELOYES _ Les Ramoncenais n auront tenu qu une ...   \n",
       "\n",
       "                                          tokens_all  \n",
       "0  [andré, bauer, le, bonhomme, de, st-dié, alain...  \n",
       "1  [le, smash, entente, club, de, lunéville, secl...  \n",
       "2  [en, tout, cas, du, côté, du, ps, dole, qui, r...  \n",
       "3  [le, nombre, des, donneurs, était, en, légère,...  \n",
       "4  [eloyes, _, les, ramoncenais, n, auront, tenu,...  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tokenisation (PARTIE 1)\n",
    "df['tokens_all']  = df.text_no_punctuation.apply(\n",
    "    lambda r : word_tokenize(r.lower())\n",
    ")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexis/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_no_punctuation</th>\n",
       "      <th>tokens_all</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>André Bauer, le Bonhomme de St-Dié ; Alain Dag...</td>\n",
       "      <td>André Bauer  le Bonhomme de St-Dié   Alain Dag...</td>\n",
       "      <td>[andré, bauer, le, bonhomme, de, st-dié, alain...</td>\n",
       "      <td>[andré, bauer, bonhomme, st-dié, alain, dagost...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Le Smash Entente Club de Lunéville (SECL) a re...</td>\n",
       "      <td>Le Smash Entente Club de Lunéville  SECL  a re...</td>\n",
       "      <td>[le, smash, entente, club, de, lunéville, secl...</td>\n",
       "      <td>[smash, entente, club, lunéville, secl, a, rep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>En tout cas, du côté du PS Dole qui reste en c...</td>\n",
       "      <td>En tout cas  du côté du PS Dole qui reste en c...</td>\n",
       "      <td>[en, tout, cas, du, côté, du, ps, dole, qui, r...</td>\n",
       "      <td>[tout, cas, côté, ps, dole, reste, course, acc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>« Le nombre des donneurs était en légère baiss...</td>\n",
       "      <td>Le nombre des donneurs était en légère baiss...</td>\n",
       "      <td>[le, nombre, des, donneurs, était, en, légère,...</td>\n",
       "      <td>[nombre, donneurs, légère, baisse, lors, derni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ELOYES._ Les Ramoncenais n'auront tenu qu'une ...</td>\n",
       "      <td>ELOYES _ Les Ramoncenais n auront tenu qu une ...</td>\n",
       "      <td>[eloyes, _, les, ramoncenais, n, auront, tenu,...</td>\n",
       "      <td>[eloyes, _, ramoncenais, tenu, heure, face, ré...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  André Bauer, le Bonhomme de St-Dié ; Alain Dag...   \n",
       "1  Le Smash Entente Club de Lunéville (SECL) a re...   \n",
       "2  En tout cas, du côté du PS Dole qui reste en c...   \n",
       "3  « Le nombre des donneurs était en légère baiss...   \n",
       "4  ELOYES._ Les Ramoncenais n'auront tenu qu'une ...   \n",
       "\n",
       "                                 text_no_punctuation  \\\n",
       "0  André Bauer  le Bonhomme de St-Dié   Alain Dag...   \n",
       "1  Le Smash Entente Club de Lunéville  SECL  a re...   \n",
       "2  En tout cas  du côté du PS Dole qui reste en c...   \n",
       "3    Le nombre des donneurs était en légère baiss...   \n",
       "4  ELOYES _ Les Ramoncenais n auront tenu qu une ...   \n",
       "\n",
       "                                          tokens_all  \\\n",
       "0  [andré, bauer, le, bonhomme, de, st-dié, alain...   \n",
       "1  [le, smash, entente, club, de, lunéville, secl...   \n",
       "2  [en, tout, cas, du, côté, du, ps, dole, qui, r...   \n",
       "3  [le, nombre, des, donneurs, était, en, légère,...   \n",
       "4  [eloyes, _, les, ramoncenais, n, auront, tenu,...   \n",
       "\n",
       "                                              tokens  \n",
       "0  [andré, bauer, bonhomme, st-dié, alain, dagost...  \n",
       "1  [smash, entente, club, lunéville, secl, a, rep...  \n",
       "2  [tout, cas, côté, ps, dole, reste, course, acc...  \n",
       "3  [nombre, donneurs, légère, baisse, lors, derni...  \n",
       "4  [eloyes, _, ramoncenais, tenu, heure, face, ré...  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove stopwords (PARTIE 3)\n",
    "\n",
    "def remove_stopword(tokens):\n",
    "     return [w for w in tokens if (w not in list_stopwords) ]\n",
    "\n",
    "# Verifier que ca marche\n",
    "#remove_stopword(tokens)\n",
    "\n",
    "# appliquer a la dataframe\n",
    "\n",
    "df['tokens'] = df.tokens_all.apply(\n",
    "    lambda tks : remove_stopword(tks) \n",
    ")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ \"Heureusement, l'affaire ne relève en rien du trafic. L'avocat de la défense fait remarquer qu'il s'agit en tout et pour tout de trente kilos de viande, d'ailleurs isolés du reste du stock, soit 6 pâtés de canard en croûtes pâtissiers, 12 taboulés et 3 mousses de canard. Juste un casse-croûte, quand la société en est à 2000 livraisons et trente tonnes vendues chaque semaine, pour un chiffre d'affaires de 30 MF annuels. « Les dates de péremption sont calculées au plus juste. Or, les produits incriminés étaient périmés d'un jour, ou d'une semaine maximum. Ils étaient encore tout à fait consommables. Et les congeler juste avant la date de péremption, c'est ce que font toutes les ménagères en gérant leur frigo ! »\",\n",
       "       'Heureusement  l affaire ne relève en rien du trafic  L avocat de la défense fait remarquer qu il s agit en tout et pour tout de trente kilos de viande  d ailleurs isolés du reste du stock  soit 6 pâtés de canard en croûtes pâtissiers  12 taboulés et 3 mousses de canard  Juste un casse-croûte  quand la société en est à 2000 livraisons et trente tonnes vendues chaque semaine  pour un chiffre d affaires de 30 MF annuels    Les dates de péremption sont calculées au plus juste  Or  les produits incriminés étaient périmés d un jour  ou d une semaine maximum  Ils étaient encore tout à fait consommables  Et les congeler juste avant la date de péremption  c est ce que font toutes les ménagères en gérant leur frigo    ',\n",
       "       list(['heureusement', 'l', 'affaire', 'ne', 'relève', 'en', 'rien', 'du', 'trafic', 'l', 'avocat', 'de', 'la', 'défense', 'fait', 'remarquer', 'qu', 'il', 's', 'agit', 'en', 'tout', 'et', 'pour', 'tout', 'de', 'trente', 'kilos', 'de', 'viande', 'd', 'ailleurs', 'isolés', 'du', 'reste', 'du', 'stock', 'soit', '6', 'pâtés', 'de', 'canard', 'en', 'croûtes', 'pâtissiers', '12', 'taboulés', 'et', '3', 'mousses', 'de', 'canard', 'juste', 'un', 'casse-croûte', 'quand', 'la', 'société', 'en', 'est', 'à', '2000', 'livraisons', 'et', 'trente', 'tonnes', 'vendues', 'chaque', 'semaine', 'pour', 'un', 'chiffre', 'd', 'affaires', 'de', '30', 'mf', 'annuels', 'les', 'dates', 'de', 'péremption', 'sont', 'calculées', 'au', 'plus', 'juste', 'or', 'les', 'produits', 'incriminés', 'étaient', 'périmés', 'd', 'un', 'jour', 'ou', 'd', 'une', 'semaine', 'maximum', 'ils', 'étaient', 'encore', 'tout', 'à', 'fait', 'consommables', 'et', 'les', 'congeler', 'juste', 'avant', 'la', 'date', 'de', 'péremption', 'c', 'est', 'ce', 'que', 'font', 'toutes', 'les', 'ménagères', 'en', 'gérant', 'leur', 'frigo']),\n",
       "       list(['heureusement', 'affaire', 'relève', 'rien', 'trafic', 'avocat', 'défense', 'fait', 'remarquer', 'agit', 'tout', 'tout', 'trente', 'kilos', 'viande', 'ailleurs', 'isolés', 'reste', 'stock', '6', 'pâtés', 'canard', 'croûtes', 'pâtissiers', '12', 'taboulés', '3', 'mousses', 'canard', 'juste', 'casse-croûte', 'quand', 'société', '2000', 'livraisons', 'trente', 'tonnes', 'vendues', 'chaque', 'semaine', 'chiffre', 'affaires', '30', 'mf', 'annuels', 'dates', 'péremption', 'calculées', 'plus', 'juste', 'or', 'produits', 'incriminés', 'périmés', 'jour', 'semaine', 'maximum', 'ils', 'encore', 'tout', 'fait', 'consommables', 'congeler', 'juste', 'avant', 'date', 'péremption', 'font', 'toutes', 'ménagères', 'gérant', 'frigo'])], dtype=object)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[5].values # m> on essaie d'appliquer sur un paragraphe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
