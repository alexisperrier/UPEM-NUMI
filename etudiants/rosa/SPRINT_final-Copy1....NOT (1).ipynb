{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexis/miniconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2728: DtypeWarning: Columns (24,25,26,28,29,31,32) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "#pandas est une  Data Analysis Library: ------> https://pandas.pydata.org/\n",
    "#on nome pandas comme pd pour agilizer l'histoire\n",
    "import pandas as pd\n",
    "\n",
    "#ou se trouve ton ficher\n",
    "DATA_PATH = './'\n",
    "#le nom de ton fichier\n",
    "filename  = 'octobre2016.csv'\n",
    "\n",
    "\n",
    "df = pd.read_csv(DATA_PATH + filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NETOGAGE DE LA BASE POUR LE TEXTE MINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Please Like and Share. The Trump Studded Banner.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It was a crisp fall morning, and the dried lea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Malik will get the supplies and send the recei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>It was a crisp fall morning, and the dried lea...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Message\n",
       "0   Please Like and Share. The Trump Studded Banner.\n",
       "1  It was a crisp fall morning, and the dried lea...\n",
       "2                                                NaN\n",
       "3  Malik will get the supplies and send the recei...\n",
       "4  It was a crisp fall morning, and the dried lea..."
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#On s'interesse que à la collone messages, \n",
    "df = df[['Message']]\n",
    "\n",
    "df[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Please Like and Share. The Trump Studded Banner.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It was a crisp fall morning, and the dried lea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Malik will get the supplies and send the recei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>It was a crisp fall morning, and the dried lea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>This would have to be the first presidential c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Message\n",
       "0   Please Like and Share. The Trump Studded Banner.\n",
       "1  It was a crisp fall morning, and the dried lea...\n",
       "3  Malik will get the supplies and send the recei...\n",
       "4  It was a crisp fall morning, and the dried lea...\n",
       "5  This would have to be the first presidential c..."
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Eliminer les cellules vides \n",
    "df=df.dropna(axis=0, how='any')\n",
    "#df[0:5] pour rester dans le 5 premierers lignes\n",
    "df[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Par respet a ton ordi, prend les 1er 100 lignes de ton data frame pour tester le code\n",
    "### me a good human, safe a CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Le corpus contient 48455 rows et 1 colonne(s)\n",
      "avant: (48455, 1)\n",
      "apres: (100, 1)\n"
     ]
    }
   ],
   "source": [
    "# #REDUCTION DE LIGNES POUR TEST DE TRAITEMENT RAPIDE\n",
    "# print(\"\\nLe corpus contient {} rows et {} colonne(s)\".format(df.shape[0], df.shape[1]))\n",
    "\n",
    "# #enlever des rows(de 0 a 100)\n",
    "# print(\"avant: {}\".format(df.shape))\n",
    "# df = df[0:100]\n",
    "\n",
    "# print(\"apres: {}\".format(df.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Il faut enlever la pontuation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Message</th>\n",
       "      <th>Message_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Please Like and Share. The Trump Studded Banner.</td>\n",
       "      <td>Please Like and Share The Trump Studded Banner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It was a crisp fall morning, and the dried lea...</td>\n",
       "      <td>It was a crisp fall morning and the dried leav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Malik will get the supplies and send the recei...</td>\n",
       "      <td>Malik will get the supplies and send the recei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>It was a crisp fall morning, and the dried lea...</td>\n",
       "      <td>It was a crisp fall morning and the dried leav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>This would have to be the first presidential c...</td>\n",
       "      <td>This would have to be the first presidential c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Message  \\\n",
       "0   Please Like and Share. The Trump Studded Banner.   \n",
       "1  It was a crisp fall morning, and the dried lea...   \n",
       "3  Malik will get the supplies and send the recei...   \n",
       "4  It was a crisp fall morning, and the dried lea...   \n",
       "5  This would have to be the first presidential c...   \n",
       "\n",
       "                                       Message_clean  \n",
       "0     Please Like and Share The Trump Studded Banner  \n",
       "1  It was a crisp fall morning and the dried leav...  \n",
       "3  Malik will get the supplies and send the recei...  \n",
       "4  It was a crisp fall morning and the dried leav...  \n",
       "5  This would have to be the first presidential c...  "
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def keep_ascii(a):\n",
    "\n",
    " text = ' '.join(re.compile('\\w+').findall(a))\n",
    "\n",
    " return ''.join([i if ord(i) < 128 else ' ' for i in text])\n",
    "\n",
    "\n",
    "df['Message_clean'] = df.Message.apply( lambda r : keep_ascii(r)  ) \n",
    "df.head()\n",
    "\n",
    "## Il faut Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Lemmatisation \n",
    "Au lieu de la tokenisation (car cette fonction tranforme deja en liste les messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import spacy\n",
    "# nlp = spacy.load('en')\n",
    "\n",
    "\n",
    "# def lemmatize(text):\n",
    "#     doc = nlp(text)\n",
    "#     return [ token.lemma_.strip() for token in doc if (token.lemma_ != '-PRON-') ]\n",
    "# df['lemmatized'] = df.Message_clean.apply(lambda d : lemmatize(d))\n",
    "# print(format(df.shape))\n",
    "# df[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization \n",
    "### -->uniquement si on a pas lemmatisé!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Message</th>\n",
       "      <th>Message_clean</th>\n",
       "      <th>tokensall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Please Like and Share. The Trump Studded Banner.</td>\n",
       "      <td>Please Like and Share The Trump Studded Banner</td>\n",
       "      <td>[please, like, and, share, the, trump, studded...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It was a crisp fall morning, and the dried lea...</td>\n",
       "      <td>It was a crisp fall morning and the dried leav...</td>\n",
       "      <td>[it, was, a, crisp, fall, morning, and, the, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Malik will get the supplies and send the recei...</td>\n",
       "      <td>Malik will get the supplies and send the recei...</td>\n",
       "      <td>[malik, will, get, the, supplies, and, send, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>It was a crisp fall morning, and the dried lea...</td>\n",
       "      <td>It was a crisp fall morning and the dried leav...</td>\n",
       "      <td>[it, was, a, crisp, fall, morning, and, the, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>This would have to be the first presidential c...</td>\n",
       "      <td>This would have to be the first presidential c...</td>\n",
       "      <td>[this, would, have, to, be, the, first, presid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Message  \\\n",
       "0   Please Like and Share. The Trump Studded Banner.   \n",
       "1  It was a crisp fall morning, and the dried lea...   \n",
       "3  Malik will get the supplies and send the recei...   \n",
       "4  It was a crisp fall morning, and the dried lea...   \n",
       "5  This would have to be the first presidential c...   \n",
       "\n",
       "                                       Message_clean  \\\n",
       "0     Please Like and Share The Trump Studded Banner   \n",
       "1  It was a crisp fall morning and the dried leav...   \n",
       "3  Malik will get the supplies and send the recei...   \n",
       "4  It was a crisp fall morning and the dried leav...   \n",
       "5  This would have to be the first presidential c...   \n",
       "\n",
       "                                           tokensall  \n",
       "0  [please, like, and, share, the, trump, studded...  \n",
       "1  [it, was, a, crisp, fall, morning, and, the, d...  \n",
       "3  [malik, will, get, the, supplies, and, send, t...  \n",
       "4  [it, was, a, crisp, fall, morning, and, the, d...  \n",
       "5  [this, would, have, to, be, the, first, presid...  "
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#On import la librerie NLTK---> http://www.nltk.org/ (is faut istaller all corpora plus punkt -un model- quand tu tape dans ta ligne de commance import nltk et puis nltk.downland())\n",
    "import nltk\n",
    "#on appelel la fonctionalite qui permet de creer des tokens\n",
    "from nltk import word_tokenize\n",
    "\n",
    "# on cree un nouvelle collone appele tokens_all pour stoker tout les tokens\n",
    "df['tokens_all']  = df.Message_clean.apply(\n",
    "   lambda r : word_tokenize(str(r).lower())\n",
    ")\n",
    "\n",
    "df[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remouve Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers', 'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', 'should', 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', 'couldn', 'didn', 'doesn', 'hadn', 'hasn', 'haven', 'isn', 'ma', 'mightn', 'mustn', 'needn', 'shan', 'shouldn', 'wasn', 'weren', 'won', 'wouldn']\n"
     ]
    }
   ],
   "source": [
    "## On fait des tokens clean sans stop words\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "#nltk a ue oction stopwords dans plusieur langues. il faut lui indiquer laquel tu veut\n",
    "\n",
    "list_stopwords = stopwords.words('english')\n",
    "print(list_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove stopwords\n",
    "\n",
    "def remove_stopword(tokens):\n",
    "     return [w for w in tokens if (w not in list_stopwords) & (len(w) > 2) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Message</th>\n",
       "      <th>Message_clean</th>\n",
       "      <th>tokensall</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Please Like and Share. The Trump Studded Banner.</td>\n",
       "      <td>Please Like and Share The Trump Studded Banner</td>\n",
       "      <td>[please, like, and, share, the, trump, studded...</td>\n",
       "      <td>[please, like, share, trump, studded, banner]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It was a crisp fall morning, and the dried lea...</td>\n",
       "      <td>It was a crisp fall morning and the dried leav...</td>\n",
       "      <td>[it, was, a, crisp, fall, morning, and, the, d...</td>\n",
       "      <td>[crisp, fall, morning, dried, leaves, flew, up...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Malik will get the supplies and send the recei...</td>\n",
       "      <td>Malik will get the supplies and send the recei...</td>\n",
       "      <td>[malik, will, get, the, supplies, and, send, t...</td>\n",
       "      <td>[malik, get, supplies, send, receipt, mexico]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>It was a crisp fall morning, and the dried lea...</td>\n",
       "      <td>It was a crisp fall morning and the dried leav...</td>\n",
       "      <td>[it, was, a, crisp, fall, morning, and, the, d...</td>\n",
       "      <td>[crisp, fall, morning, dried, leaves, flew, up...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>This would have to be the first presidential c...</td>\n",
       "      <td>This would have to be the first presidential c...</td>\n",
       "      <td>[this, would, have, to, be, the, first, presid...</td>\n",
       "      <td>[would, first, presidential, candidate, fanfic...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Message  \\\n",
       "0   Please Like and Share. The Trump Studded Banner.   \n",
       "1  It was a crisp fall morning, and the dried lea...   \n",
       "3  Malik will get the supplies and send the recei...   \n",
       "4  It was a crisp fall morning, and the dried lea...   \n",
       "5  This would have to be the first presidential c...   \n",
       "\n",
       "                                       Message_clean  \\\n",
       "0     Please Like and Share The Trump Studded Banner   \n",
       "1  It was a crisp fall morning and the dried leav...   \n",
       "3  Malik will get the supplies and send the recei...   \n",
       "4  It was a crisp fall morning and the dried leav...   \n",
       "5  This would have to be the first presidential c...   \n",
       "\n",
       "                                           tokensall  \\\n",
       "0  [please, like, and, share, the, trump, studded...   \n",
       "1  [it, was, a, crisp, fall, morning, and, the, d...   \n",
       "3  [malik, will, get, the, supplies, and, send, t...   \n",
       "4  [it, was, a, crisp, fall, morning, and, the, d...   \n",
       "5  [this, would, have, to, be, the, first, presid...   \n",
       "\n",
       "                                              tokens  \n",
       "0      [please, like, share, trump, studded, banner]  \n",
       "1  [crisp, fall, morning, dried, leaves, flew, up...  \n",
       "3      [malik, get, supplies, send, receipt, mexico]  \n",
       "4  [crisp, fall, morning, dried, leaves, flew, up...  \n",
       "5  [would, first, presidential, candidate, fanfic...  "
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ici on peut mettre lemmatized si on a lemmatizer ou token_all si on a tokeniser!!!!!!!\n",
    "\n",
    "df['tokens'] = df.tokensall.apply(\n",
    "    lambda tks : remove_stopword(tks) \n",
    ")\n",
    "df[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nombre de tokens par rangée\n",
    "pd.options.mode.chained_assignment = None\n",
    "df['token_count'] = df.tokens.apply( lambda r : len(r) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Message_clean', 'tokens', 'token_count'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Message_clean</th>\n",
       "      <th>tokens</th>\n",
       "      <th>token_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Please Like and Share The Trump Studded Banner</td>\n",
       "      <td>[please, like, share, trump, studded, banner]</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It was a crisp fall morning and the dried leav...</td>\n",
       "      <td>[crisp, fall, morning, dried, leaves, flew, up...</td>\n",
       "      <td>176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Malik will get the supplies and send the recei...</td>\n",
       "      <td>[malik, get, supplies, send, receipt, mexico]</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>It was a crisp fall morning and the dried leav...</td>\n",
       "      <td>[crisp, fall, morning, dried, leaves, flew, up...</td>\n",
       "      <td>176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>This would have to be the first presidential c...</td>\n",
       "      <td>[would, first, presidential, candidate, fanfic...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Message_clean  \\\n",
       "0     Please Like and Share The Trump Studded Banner   \n",
       "1  It was a crisp fall morning and the dried leav...   \n",
       "3  Malik will get the supplies and send the recei...   \n",
       "4  It was a crisp fall morning and the dried leav...   \n",
       "5  This would have to be the first presidential c...   \n",
       "\n",
       "                                              tokens  token_count  \n",
       "0      [please, like, share, trump, studded, banner]            6  \n",
       "1  [crisp, fall, morning, dried, leaves, flew, up...          176  \n",
       "3      [malik, get, supplies, send, receipt, mexico]            6  \n",
       "4  [crisp, fall, morning, dried, leaves, flew, up...          176  \n",
       "5  [would, first, presidential, candidate, fanfic...           10  "
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# enlever les colonnes intermediaires\n",
    "\n",
    "\n",
    "df = df[['Message_clean', 'tokens', 'token_count']]\n",
    "\n",
    "print(df.columns)\n",
    "df[0:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    48455.000000\n",
      "mean         5.918894\n",
      "std         11.991215\n",
      "min          0.000000\n",
      "25%          2.000000\n",
      "50%          3.000000\n",
      "75%          6.000000\n",
      "max        306.000000\n",
      "Name: token_count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# repartition du nombre de tokens pour voir les valeurs extremes\n",
    "print(df.token_count.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">300\n",
      "(1, 3)\n",
      ">200\n",
      "(16, 3)\n",
      ">100\n",
      "(152, 3)\n",
      ">50\n",
      "(378, 3)\n",
      ">10\n",
      "(5547, 3)\n",
      ">5\n",
      "(14042, 3)\n",
      ">1\n",
      "(41924, 3)\n"
     ]
    }
   ],
   "source": [
    "#si on veut voir se que ca donne a plusieur chiffres\n",
    "\n",
    "print('>300')\n",
    "condition2 = (df.token_count > 300)\n",
    "print(df[condition2].shape)\n",
    "\n",
    "print('>200')\n",
    "condition2 = (df.token_count > 200 )\n",
    "print(df[condition2].shape)\n",
    "\n",
    "print('>100')\n",
    "condition2 = (df.token_count > 100)\n",
    "print(df[condition2].shape)\n",
    "\n",
    "print('>50')\n",
    "condition2 = (df.token_count > 50)\n",
    "print(df[condition2].shape)\n",
    "\n",
    "print('>10')\n",
    "condition2 = (df.token_count > 10)\n",
    "print(df[condition2].shape)\n",
    "\n",
    "print('>5')\n",
    "condition2 = (df.token_count > 5)\n",
    "print(df[condition2].shape)\n",
    "\n",
    "print('>1')\n",
    "condition2 = (df.token_count > 1)\n",
    "print(df[condition2].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 'pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe pepe']\n"
     ]
    }
   ],
   "source": [
    "#on voit qu'il y a des valeur dispersés, surtout dans les extremes\n",
    "# Un comment avec trop de tokens, on essaye de voir lequel et pourquoi:\n",
    "condition = (df.token_count > 300)\n",
    "print(df[condition].Message_clean.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Message_clean</th>\n",
       "      <th>tokens</th>\n",
       "      <th>token_count</th>\n",
       "      <th>uniq_tokens</th>\n",
       "      <th>uniq_tokens_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Please Like and Share The Trump Studded Banner</td>\n",
       "      <td>[please, like, share, trump, studded, banner]</td>\n",
       "      <td>6</td>\n",
       "      <td>[like, share, studded, trump, banner, please]</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It was a crisp fall morning and the dried leav...</td>\n",
       "      <td>[crisp, fall, morning, dried, leaves, flew, up...</td>\n",
       "      <td>176</td>\n",
       "      <td>[americans, upon, father, street, sweetie, bro...</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Malik will get the supplies and send the recei...</td>\n",
       "      <td>[malik, get, supplies, send, receipt, mexico]</td>\n",
       "      <td>6</td>\n",
       "      <td>[send, get, supplies, mexico, receipt, malik]</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>It was a crisp fall morning and the dried leav...</td>\n",
       "      <td>[crisp, fall, morning, dried, leaves, flew, up...</td>\n",
       "      <td>176</td>\n",
       "      <td>[americans, upon, father, street, sweetie, bro...</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>This would have to be the first presidential c...</td>\n",
       "      <td>[would, first, presidential, candidate, fanfic...</td>\n",
       "      <td>10</td>\n",
       "      <td>[maybe, enough, presidential, hard, fanfic, wr...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>its funny as a Canadian i took interest in Ame...</td>\n",
       "      <td>[funny, canadian, took, interest, american, po...</td>\n",
       "      <td>84</td>\n",
       "      <td>[hillary, americans, put, lead, consideration,...</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>If Trump gets in it s gonna be bad for Canada ...</td>\n",
       "      <td>[trump, gets, gon, bad, canada, gon, get, cryb...</td>\n",
       "      <td>27</td>\n",
       "      <td>[get, disagreed, hunting, triggered, vegetaria...</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Send the SJWs to the NWT Nunavut or even the Y...</td>\n",
       "      <td>[send, sjws, nwt, nunavut, even, yukon, territ...</td>\n",
       "      <td>17</td>\n",
       "      <td>[send, territory, plenty, room, bonus, among, ...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Is Malik going be in Laredo Tx in the next thr...</td>\n",
       "      <td>[malik, going, laredo, next, three, days, dos,...</td>\n",
       "      <td>13</td>\n",
       "      <td>[wall, dos, going, job, nights, help, days, la...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>We have the best Obamas don t we folks</td>\n",
       "      <td>[best, obamas, folks]</td>\n",
       "      <td>3</td>\n",
       "      <td>[folks, obamas, best]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Go Trump My bird is Trump 2016</td>\n",
       "      <td>[trump, bird, trump, 2016]</td>\n",
       "      <td>4</td>\n",
       "      <td>[2016, trump, bird]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>We must build a cage and make the cats pay for it</td>\n",
       "      <td>[must, build, cage, make, cats, pay]</td>\n",
       "      <td>6</td>\n",
       "      <td>[cage, cats, make, build, must, pay]</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Myles Macinnes I have a US partner and we supo...</td>\n",
       "      <td>[myles, macinnes, partner, suport, trump, comp...</td>\n",
       "      <td>9</td>\n",
       "      <td>[jobs, macinnes, taxes, less, myles, trump, co...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Maga</td>\n",
       "      <td>[maga]</td>\n",
       "      <td>1</td>\n",
       "      <td>[maga]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>MAGA</td>\n",
       "      <td>[maga]</td>\n",
       "      <td>1</td>\n",
       "      <td>[maga]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>MAGA</td>\n",
       "      <td>[maga]</td>\n",
       "      <td>1</td>\n",
       "      <td>[maga]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Shit I ll fly down and help myself and I ve ne...</td>\n",
       "      <td>[shit, fly, help, never, done, sort, construct...</td>\n",
       "      <td>8</td>\n",
       "      <td>[fly, never, help, sort, done, construction, s...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>It looks like we ll be taking a trip to the ha...</td>\n",
       "      <td>[looks, like, taking, trip, hardware, store]</td>\n",
       "      <td>6</td>\n",
       "      <td>[store, looks, like, trip, hardware, taking]</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>For a hammer and some dubya dee forty</td>\n",
       "      <td>[hammer, dubya, dee, forty]</td>\n",
       "      <td>4</td>\n",
       "      <td>[hammer, dee, forty, dubya]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Yup Tosses you an Alamo</td>\n",
       "      <td>[yup, tosses, alamo]</td>\n",
       "      <td>3</td>\n",
       "      <td>[alamo, yup, tosses]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>No Home Depot at 6 30 AM is where you go to fi...</td>\n",
       "      <td>[home, depot, find, people, belong, side, wall]</td>\n",
       "      <td>7</td>\n",
       "      <td>[side, wall, belong, depot, find, home, people]</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>I want to chill with this malik guy Seems like...</td>\n",
       "      <td>[want, chill, malik, guy, seems, like, total, ...</td>\n",
       "      <td>14</td>\n",
       "      <td>[bro, total, brother, guy, like, looks, guess,...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>I dub this guy Mic drop Malik The True Bama se...</td>\n",
       "      <td>[dub, guy, mic, drop, malik, true, bama, sent,...</td>\n",
       "      <td>17</td>\n",
       "      <td>[high, slay, mic, kek, true, guy, bama, lord, ...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>PRAISE KEK</td>\n",
       "      <td>[praise, kek]</td>\n",
       "      <td>2</td>\n",
       "      <td>[praise, kek]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>What the hell does this Hut dweller know about...</td>\n",
       "      <td>[hell, hut, dweller, know, america, politics]</td>\n",
       "      <td>6</td>\n",
       "      <td>[hut, dweller, know, america, politics, hell]</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>He s a US citizen As much as anyone else</td>\n",
       "      <td>[citizen, much, anyone, else]</td>\n",
       "      <td>4</td>\n",
       "      <td>[citizen, much, else, anyone]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>I didn t know he had dual citizenship</td>\n",
       "      <td>[know, dual, citizenship]</td>\n",
       "      <td>3</td>\n",
       "      <td>[citizenship, know, dual]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>shit half of mexico is in the home depot parki...</td>\n",
       "      <td>[shit, half, mexico, home, depot, parking, lot]</td>\n",
       "      <td>7</td>\n",
       "      <td>[parking, mexico, half, depot, lot, home, shit]</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>If you go to Home Depot early in the morning y...</td>\n",
       "      <td>[home, depot, early, morning, even, hire, mexi...</td>\n",
       "      <td>8</td>\n",
       "      <td>[cheap, morning, depot, mexicans, even, home, ...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>David Gowan Jr I can t help but to find this i...</td>\n",
       "      <td>[david, gowan, help, find, indeed, find, funny]</td>\n",
       "      <td>7</td>\n",
       "      <td>[david, funny, find, indeed, help, gowan]</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52654</th>\n",
       "      <td>hahahahha and you d be right xD</td>\n",
       "      <td>[hahahahha, right]</td>\n",
       "      <td>2</td>\n",
       "      <td>[right, hahahahha]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52655</th>\n",
       "      <td>Ryan Anliker harambe</td>\n",
       "      <td>[ryan, anliker, harambe]</td>\n",
       "      <td>3</td>\n",
       "      <td>[harambe, ryan, anliker]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52656</th>\n",
       "      <td>Darren Snedden Matthew Mcmillan</td>\n",
       "      <td>[darren, snedden, matthew, mcmillan]</td>\n",
       "      <td>4</td>\n",
       "      <td>[mcmillan, darren, snedden, matthew]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52657</th>\n",
       "      <td>Cameron Watson Brad West Oliver Newrick Tom Be...</td>\n",
       "      <td>[cameron, watson, brad, west, oliver, newrick,...</td>\n",
       "      <td>10</td>\n",
       "      <td>[newrick, isaac, cameron, brad, oliver, lowthe...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52658</th>\n",
       "      <td>Reen Willier Nick Garcia Jennifer Escalante</td>\n",
       "      <td>[reen, willier, nick, garcia, jennifer, escala...</td>\n",
       "      <td>6</td>\n",
       "      <td>[jennifer, nick, garcia, escalante, reen, will...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52659</th>\n",
       "      <td>Noah Knight Marlow</td>\n",
       "      <td>[noah, knight, marlow]</td>\n",
       "      <td>3</td>\n",
       "      <td>[knight, marlow, noah]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52660</th>\n",
       "      <td>Grasen Alexander</td>\n",
       "      <td>[grasen, alexander]</td>\n",
       "      <td>2</td>\n",
       "      <td>[alexander, grasen]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52661</th>\n",
       "      <td>Connor Patrick Macloud</td>\n",
       "      <td>[connor, patrick, macloud]</td>\n",
       "      <td>3</td>\n",
       "      <td>[connor, macloud, patrick]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52662</th>\n",
       "      <td>Nicole Amanda Nieto Qui onez</td>\n",
       "      <td>[nicole, amanda, nieto, qui, onez]</td>\n",
       "      <td>5</td>\n",
       "      <td>[qui, amanda, nieto, onez, nicole]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52663</th>\n",
       "      <td>Josh Garn Mason Maxwell</td>\n",
       "      <td>[josh, garn, mason, maxwell]</td>\n",
       "      <td>4</td>\n",
       "      <td>[mason, josh, garn, maxwell]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52664</th>\n",
       "      <td>Laura Giannoni</td>\n",
       "      <td>[laura, giannoni]</td>\n",
       "      <td>2</td>\n",
       "      <td>[giannoni, laura]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52665</th>\n",
       "      <td>Ma secondo te tutte ste pagine di meme support...</td>\n",
       "      <td>[secondo, tutte, ste, pagine, meme, supportano...</td>\n",
       "      <td>14</td>\n",
       "      <td>[meme, ste, davvero, supportano, tutte, second...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52666</th>\n",
       "      <td>Per davvero</td>\n",
       "      <td>[per, davvero]</td>\n",
       "      <td>2</td>\n",
       "      <td>[per, davvero]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52667</th>\n",
       "      <td>Ma   anche divertente allietare il dovere con ...</td>\n",
       "      <td>[anche, divertente, allietare, dovere, con, qu...</td>\n",
       "      <td>7</td>\n",
       "      <td>[dovere, meme, divertente, allietare, qualche,...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52668</th>\n",
       "      <td>Ma   un coglione Fanno meme belli ma lui   un ...</td>\n",
       "      <td>[coglione, fanno, meme, belli, lui, coglione]</td>\n",
       "      <td>6</td>\n",
       "      <td>[meme, lui, belli, fanno, coglione]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52669</th>\n",
       "      <td>Seh</td>\n",
       "      <td>[seh]</td>\n",
       "      <td>1</td>\n",
       "      <td>[seh]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52670</th>\n",
       "      <td>Nick Roche</td>\n",
       "      <td>[nick, roche]</td>\n",
       "      <td>2</td>\n",
       "      <td>[nick, roche]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52671</th>\n",
       "      <td>Rudy Arguelles III</td>\n",
       "      <td>[rudy, arguelles, iii]</td>\n",
       "      <td>3</td>\n",
       "      <td>[arguelles, iii, rudy]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52672</th>\n",
       "      <td>Willie Willow</td>\n",
       "      <td>[willie, willow]</td>\n",
       "      <td>2</td>\n",
       "      <td>[willow, willie]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52673</th>\n",
       "      <td>Matt</td>\n",
       "      <td>[matt]</td>\n",
       "      <td>1</td>\n",
       "      <td>[matt]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52674</th>\n",
       "      <td>Jorge Hanel</td>\n",
       "      <td>[jorge, hanel]</td>\n",
       "      <td>2</td>\n",
       "      <td>[jorge, hanel]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52675</th>\n",
       "      <td>Harambe vult</td>\n",
       "      <td>[harambe, vult]</td>\n",
       "      <td>2</td>\n",
       "      <td>[harambe, vult]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52676</th>\n",
       "      <td>Austin Tezak</td>\n",
       "      <td>[austin, tezak]</td>\n",
       "      <td>2</td>\n",
       "      <td>[austin, tezak]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52677</th>\n",
       "      <td>Sol Pattie</td>\n",
       "      <td>[sol, pattie]</td>\n",
       "      <td>2</td>\n",
       "      <td>[sol, pattie]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52678</th>\n",
       "      <td>Muhammad Arayne</td>\n",
       "      <td>[muhammad, arayne]</td>\n",
       "      <td>2</td>\n",
       "      <td>[arayne, muhammad]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52679</th>\n",
       "      <td>How did you even find this page</td>\n",
       "      <td>[even, find, page]</td>\n",
       "      <td>3</td>\n",
       "      <td>[find, page, even]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52680</th>\n",
       "      <td>Idk but I m having a horrific time reading it rn</td>\n",
       "      <td>[idk, horrific, time, reading]</td>\n",
       "      <td>4</td>\n",
       "      <td>[reading, idk, time, horrific]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52681</th>\n",
       "      <td>Jay Cuckler</td>\n",
       "      <td>[jay, cuckler]</td>\n",
       "      <td>2</td>\n",
       "      <td>[jay, cuckler]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52682</th>\n",
       "      <td>True art</td>\n",
       "      <td>[true, art]</td>\n",
       "      <td>2</td>\n",
       "      <td>[true, art]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52683</th>\n",
       "      <td>Rosie Bird</td>\n",
       "      <td>[rosie, bird]</td>\n",
       "      <td>2</td>\n",
       "      <td>[bird, rosie]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48455 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Message_clean  \\\n",
       "0         Please Like and Share The Trump Studded Banner   \n",
       "1      It was a crisp fall morning and the dried leav...   \n",
       "3      Malik will get the supplies and send the recei...   \n",
       "4      It was a crisp fall morning and the dried leav...   \n",
       "5      This would have to be the first presidential c...   \n",
       "7      its funny as a Canadian i took interest in Ame...   \n",
       "8      If Trump gets in it s gonna be bad for Canada ...   \n",
       "9      Send the SJWs to the NWT Nunavut or even the Y...   \n",
       "10     Is Malik going be in Laredo Tx in the next thr...   \n",
       "11                We have the best Obamas don t we folks   \n",
       "12                        Go Trump My bird is Trump 2016   \n",
       "13     We must build a cage and make the cats pay for it   \n",
       "14     Myles Macinnes I have a US partner and we supo...   \n",
       "15                                                  Maga   \n",
       "16                                                  MAGA   \n",
       "17                                                  MAGA   \n",
       "18     Shit I ll fly down and help myself and I ve ne...   \n",
       "19     It looks like we ll be taking a trip to the ha...   \n",
       "20                 For a hammer and some dubya dee forty   \n",
       "21                               Yup Tosses you an Alamo   \n",
       "22     No Home Depot at 6 30 AM is where you go to fi...   \n",
       "23     I want to chill with this malik guy Seems like...   \n",
       "24     I dub this guy Mic drop Malik The True Bama se...   \n",
       "25                                            PRAISE KEK   \n",
       "26     What the hell does this Hut dweller know about...   \n",
       "27              He s a US citizen As much as anyone else   \n",
       "28                 I didn t know he had dual citizenship   \n",
       "29     shit half of mexico is in the home depot parki...   \n",
       "30     If you go to Home Depot early in the morning y...   \n",
       "31     David Gowan Jr I can t help but to find this i...   \n",
       "...                                                  ...   \n",
       "52654                    hahahahha and you d be right xD   \n",
       "52655                               Ryan Anliker harambe   \n",
       "52656                    Darren Snedden Matthew Mcmillan   \n",
       "52657  Cameron Watson Brad West Oliver Newrick Tom Be...   \n",
       "52658        Reen Willier Nick Garcia Jennifer Escalante   \n",
       "52659                                 Noah Knight Marlow   \n",
       "52660                                   Grasen Alexander   \n",
       "52661                             Connor Patrick Macloud   \n",
       "52662                       Nicole Amanda Nieto Qui onez   \n",
       "52663                            Josh Garn Mason Maxwell   \n",
       "52664                                     Laura Giannoni   \n",
       "52665  Ma secondo te tutte ste pagine di meme support...   \n",
       "52666                                        Per davvero   \n",
       "52667  Ma   anche divertente allietare il dovere con ...   \n",
       "52668  Ma   un coglione Fanno meme belli ma lui   un ...   \n",
       "52669                                                Seh   \n",
       "52670                                         Nick Roche   \n",
       "52671                                 Rudy Arguelles III   \n",
       "52672                                      Willie Willow   \n",
       "52673                                               Matt   \n",
       "52674                                        Jorge Hanel   \n",
       "52675                                       Harambe vult   \n",
       "52676                                       Austin Tezak   \n",
       "52677                                         Sol Pattie   \n",
       "52678                                    Muhammad Arayne   \n",
       "52679                    How did you even find this page   \n",
       "52680   Idk but I m having a horrific time reading it rn   \n",
       "52681                                        Jay Cuckler   \n",
       "52682                                           True art   \n",
       "52683                                         Rosie Bird   \n",
       "\n",
       "                                                  tokens  token_count  \\\n",
       "0          [please, like, share, trump, studded, banner]            6   \n",
       "1      [crisp, fall, morning, dried, leaves, flew, up...          176   \n",
       "3          [malik, get, supplies, send, receipt, mexico]            6   \n",
       "4      [crisp, fall, morning, dried, leaves, flew, up...          176   \n",
       "5      [would, first, presidential, candidate, fanfic...           10   \n",
       "7      [funny, canadian, took, interest, american, po...           84   \n",
       "8      [trump, gets, gon, bad, canada, gon, get, cryb...           27   \n",
       "9      [send, sjws, nwt, nunavut, even, yukon, territ...           17   \n",
       "10     [malik, going, laredo, next, three, days, dos,...           13   \n",
       "11                                 [best, obamas, folks]            3   \n",
       "12                            [trump, bird, trump, 2016]            4   \n",
       "13                  [must, build, cage, make, cats, pay]            6   \n",
       "14     [myles, macinnes, partner, suport, trump, comp...            9   \n",
       "15                                                [maga]            1   \n",
       "16                                                [maga]            1   \n",
       "17                                                [maga]            1   \n",
       "18     [shit, fly, help, never, done, sort, construct...            8   \n",
       "19          [looks, like, taking, trip, hardware, store]            6   \n",
       "20                           [hammer, dubya, dee, forty]            4   \n",
       "21                                  [yup, tosses, alamo]            3   \n",
       "22       [home, depot, find, people, belong, side, wall]            7   \n",
       "23     [want, chill, malik, guy, seems, like, total, ...           14   \n",
       "24     [dub, guy, mic, drop, malik, true, bama, sent,...           17   \n",
       "25                                         [praise, kek]            2   \n",
       "26         [hell, hut, dweller, know, america, politics]            6   \n",
       "27                         [citizen, much, anyone, else]            4   \n",
       "28                             [know, dual, citizenship]            3   \n",
       "29       [shit, half, mexico, home, depot, parking, lot]            7   \n",
       "30     [home, depot, early, morning, even, hire, mexi...            8   \n",
       "31       [david, gowan, help, find, indeed, find, funny]            7   \n",
       "...                                                  ...          ...   \n",
       "52654                                 [hahahahha, right]            2   \n",
       "52655                           [ryan, anliker, harambe]            3   \n",
       "52656               [darren, snedden, matthew, mcmillan]            4   \n",
       "52657  [cameron, watson, brad, west, oliver, newrick,...           10   \n",
       "52658  [reen, willier, nick, garcia, jennifer, escala...            6   \n",
       "52659                             [noah, knight, marlow]            3   \n",
       "52660                                [grasen, alexander]            2   \n",
       "52661                         [connor, patrick, macloud]            3   \n",
       "52662                 [nicole, amanda, nieto, qui, onez]            5   \n",
       "52663                       [josh, garn, mason, maxwell]            4   \n",
       "52664                                  [laura, giannoni]            2   \n",
       "52665  [secondo, tutte, ste, pagine, meme, supportano...           14   \n",
       "52666                                     [per, davvero]            2   \n",
       "52667  [anche, divertente, allietare, dovere, con, qu...            7   \n",
       "52668      [coglione, fanno, meme, belli, lui, coglione]            6   \n",
       "52669                                              [seh]            1   \n",
       "52670                                      [nick, roche]            2   \n",
       "52671                             [rudy, arguelles, iii]            3   \n",
       "52672                                   [willie, willow]            2   \n",
       "52673                                             [matt]            1   \n",
       "52674                                     [jorge, hanel]            2   \n",
       "52675                                    [harambe, vult]            2   \n",
       "52676                                    [austin, tezak]            2   \n",
       "52677                                      [sol, pattie]            2   \n",
       "52678                                 [muhammad, arayne]            2   \n",
       "52679                                 [even, find, page]            3   \n",
       "52680                     [idk, horrific, time, reading]            4   \n",
       "52681                                     [jay, cuckler]            2   \n",
       "52682                                        [true, art]            2   \n",
       "52683                                      [rosie, bird]            2   \n",
       "\n",
       "                                             uniq_tokens  uniq_tokens_count  \n",
       "0          [like, share, studded, trump, banner, please]                  6  \n",
       "1      [americans, upon, father, street, sweetie, bro...                139  \n",
       "3          [send, get, supplies, mexico, receipt, malik]                  6  \n",
       "4      [americans, upon, father, street, sweetie, bro...                139  \n",
       "5      [maybe, enough, presidential, hard, fanfic, wr...                 10  \n",
       "7      [hillary, americans, put, lead, consideration,...                 75  \n",
       "8      [get, disagreed, hunting, triggered, vegetaria...                 24  \n",
       "9      [send, territory, plenty, room, bonus, among, ...                 16  \n",
       "10     [wall, dos, going, job, nights, help, days, la...                 13  \n",
       "11                                 [folks, obamas, best]                  3  \n",
       "12                                   [2016, trump, bird]                  3  \n",
       "13                  [cage, cats, make, build, must, pay]                  6  \n",
       "14     [jobs, macinnes, taxes, less, myles, trump, co...                  9  \n",
       "15                                                [maga]                  1  \n",
       "16                                                [maga]                  1  \n",
       "17                                                [maga]                  1  \n",
       "18     [fly, never, help, sort, done, construction, s...                  8  \n",
       "19          [store, looks, like, trip, hardware, taking]                  6  \n",
       "20                           [hammer, dee, forty, dubya]                  4  \n",
       "21                                  [alamo, yup, tosses]                  3  \n",
       "22       [side, wall, belong, depot, find, home, people]                  7  \n",
       "23     [bro, total, brother, guy, like, looks, guess,...                 13  \n",
       "24     [high, slay, mic, kek, true, guy, bama, lord, ...                 17  \n",
       "25                                         [praise, kek]                  2  \n",
       "26         [hut, dweller, know, america, politics, hell]                  6  \n",
       "27                         [citizen, much, else, anyone]                  4  \n",
       "28                             [citizenship, know, dual]                  3  \n",
       "29       [parking, mexico, half, depot, lot, home, shit]                  7  \n",
       "30     [cheap, morning, depot, mexicans, even, home, ...                  8  \n",
       "31             [david, funny, find, indeed, help, gowan]                  6  \n",
       "...                                                  ...                ...  \n",
       "52654                                 [right, hahahahha]                  2  \n",
       "52655                           [harambe, ryan, anliker]                  3  \n",
       "52656               [mcmillan, darren, snedden, matthew]                  4  \n",
       "52657  [newrick, isaac, cameron, brad, oliver, lowthe...                 10  \n",
       "52658  [jennifer, nick, garcia, escalante, reen, will...                  6  \n",
       "52659                             [knight, marlow, noah]                  3  \n",
       "52660                                [alexander, grasen]                  2  \n",
       "52661                         [connor, macloud, patrick]                  3  \n",
       "52662                 [qui, amanda, nieto, onez, nicole]                  5  \n",
       "52663                       [mason, josh, garn, maxwell]                  4  \n",
       "52664                                  [giannoni, laura]                  2  \n",
       "52665  [meme, ste, davvero, supportano, tutte, second...                 13  \n",
       "52666                                     [per, davvero]                  2  \n",
       "52667  [dovere, meme, divertente, allietare, qualche,...                  7  \n",
       "52668                [meme, lui, belli, fanno, coglione]                  5  \n",
       "52669                                              [seh]                  1  \n",
       "52670                                      [nick, roche]                  2  \n",
       "52671                             [arguelles, iii, rudy]                  3  \n",
       "52672                                   [willow, willie]                  2  \n",
       "52673                                             [matt]                  1  \n",
       "52674                                     [jorge, hanel]                  2  \n",
       "52675                                    [harambe, vult]                  2  \n",
       "52676                                    [austin, tezak]                  2  \n",
       "52677                                      [sol, pattie]                  2  \n",
       "52678                                 [arayne, muhammad]                  2  \n",
       "52679                                 [find, page, even]                  3  \n",
       "52680                     [reading, idk, time, horrific]                  4  \n",
       "52681                                     [jay, cuckler]                  2  \n",
       "52682                                        [true, art]                  2  \n",
       "52683                                      [bird, rosie]                  2  \n",
       "\n",
       "[48455 rows x 5 columns]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#On voit que c'est le meme token donc:\n",
    "# POUR ENLEVER LES REPETÉES\n",
    "df['uniq_tokens'] = df.tokens.apply( lambda tk : list(set(tk)) )\n",
    "\n",
    "#pour voir les diferences on peut refaire le token_count sur Uniq_tokens\n",
    "pd.options.mode.chained_assignment = None\n",
    "df['uniq_tokens_count'] = df.uniq_tokens.apply( lambda r : len(r) )\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    48455.000000\n",
      "mean         5.864493\n",
      "std         11.900341\n",
      "min          0.000000\n",
      "25%          2.000000\n",
      "50%          3.000000\n",
      "75%          6.000000\n",
      "max        306.000000\n",
      "Name: token_count, dtype: float64\n",
      "count    48455.000000\n",
      "mean         5.495037\n",
      "std          9.409468\n",
      "min          0.000000\n",
      "25%          2.000000\n",
      "50%          3.000000\n",
      "75%          6.000000\n",
      "max        233.000000\n",
      "Name: uniq_tokens_count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#et on refait la distribution pour les comparées:\n",
    "print(df.token_count.describe())\n",
    "print(df.uniq_tokens_count.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Message_clean', 'tokens', 'token_count', 'uniq_tokens',\n",
      "       'uniq_tokens_count'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Message_clean</th>\n",
       "      <th>tokens</th>\n",
       "      <th>token_count</th>\n",
       "      <th>uniq_tokens</th>\n",
       "      <th>uniq_tokens_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30563</th>\n",
       "      <td>XD</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21554</th>\n",
       "      <td>For now</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33974</th>\n",
       "      <td>Me too</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6620</th>\n",
       "      <td>All of the above</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49690</th>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40142</th>\n",
       "      <td>Who</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7557</th>\n",
       "      <td>Why</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49691</th>\n",
       "      <td>if if if if if if if if if if if</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6148</th>\n",
       "      <td>If only</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5334</th>\n",
       "      <td>She shouldn t</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49692</th>\n",
       "      <td>WE</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1755</th>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6615</th>\n",
       "      <td>F R E E H E L I C O P T E R R I D E S</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38791</th>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39623</th>\n",
       "      <td>Se n</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47466</th>\n",
       "      <td>Who s we</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6609</th>\n",
       "      <td>d all the above</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5346</th>\n",
       "      <td>Jo o</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49035</th>\n",
       "      <td>Will</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39617</th>\n",
       "      <td>Oh no you di n t</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30549</th>\n",
       "      <td>W E L L D O N E</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10742</th>\n",
       "      <td>2 to a 1</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51514</th>\n",
       "      <td>C U R R E N T Y E A R U R R E N T Y E A R</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51515</th>\n",
       "      <td>S U I C I D E U I C I D E W A T C H A T C H</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3477</th>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7995</th>\n",
       "      <td>xD</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39602</th>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37073</th>\n",
       "      <td>ok</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9070</th>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7576</th>\n",
       "      <td>Same with me</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28393</th>\n",
       "      <td>The Book The experiment military theological S...</td>\n",
       "      <td>[book, experiment, military, theological, s666...</td>\n",
       "      <td>217</td>\n",
       "      <td>[tarot, sasso, book, roman, street, november, ...</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10366</th>\n",
       "      <td>A bit long but a must read Subject Who is Tim ...</td>\n",
       "      <td>[bit, long, must, read, subject, tim, kaine, c...</td>\n",
       "      <td>196</td>\n",
       "      <td>[street, overt, imam, father, runs, ties, top,...</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11160</th>\n",
       "      <td>A bit long but a must read Subject Who is Tim ...</td>\n",
       "      <td>[bit, long, must, read, subject, tim, kaine, c...</td>\n",
       "      <td>196</td>\n",
       "      <td>[street, overt, imam, father, runs, ties, top,...</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7293</th>\n",
       "      <td>Mine too Must read One step from being Preside...</td>\n",
       "      <td>[mine, must, read, one, step, president, subje...</td>\n",
       "      <td>196</td>\n",
       "      <td>[street, overt, imam, father, runs, ties, top,...</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9496</th>\n",
       "      <td>One step from Potus if Hillary is elected read...</td>\n",
       "      <td>[one, step, potus, hillary, elected, read, sub...</td>\n",
       "      <td>196</td>\n",
       "      <td>[street, overt, imam, father, runs, ties, top,...</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26719</th>\n",
       "      <td>The fact that she has good policies the fact t...</td>\n",
       "      <td>[fact, good, policies, fact, fit, potus, email...</td>\n",
       "      <td>180</td>\n",
       "      <td>[fit, americans, collectively, stance, entirel...</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6260</th>\n",
       "      <td>Must read One step from being President Subjec...</td>\n",
       "      <td>[must, read, one, step, president, subject, ti...</td>\n",
       "      <td>197</td>\n",
       "      <td>[street, overt, imam, father, runs, ties, top,...</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9641</th>\n",
       "      <td>One step from Potus if Hillary is elected read...</td>\n",
       "      <td>[one, step, potus, hillary, elected, read, sub...</td>\n",
       "      <td>196</td>\n",
       "      <td>[street, overt, imam, father, runs, ties, top,...</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10097</th>\n",
       "      <td>A bit long but a must read Subject Who is Tim ...</td>\n",
       "      <td>[bit, long, must, read, subject, tim, kaine, c...</td>\n",
       "      <td>196</td>\n",
       "      <td>[street, overt, imam, father, runs, ties, top,...</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10115</th>\n",
       "      <td>A bit long but a must read Subject Who is Tim ...</td>\n",
       "      <td>[bit, long, must, read, subject, tim, kaine, c...</td>\n",
       "      <td>196</td>\n",
       "      <td>[street, overt, imam, father, runs, ties, top,...</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10467</th>\n",
       "      <td>A bit long but a must read Subject Who is Tim ...</td>\n",
       "      <td>[bit, long, must, read, subject, tim, kaine, c...</td>\n",
       "      <td>196</td>\n",
       "      <td>[street, overt, imam, father, runs, ties, top,...</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10486</th>\n",
       "      <td>A bit long but a must read Subject Who is Tim ...</td>\n",
       "      <td>[bit, long, must, read, subject, tim, kaine, c...</td>\n",
       "      <td>196</td>\n",
       "      <td>[street, overt, imam, father, runs, ties, top,...</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10517</th>\n",
       "      <td>A bit long but a must read Subject Who is Tim ...</td>\n",
       "      <td>[bit, long, must, read, subject, tim, kaine, c...</td>\n",
       "      <td>196</td>\n",
       "      <td>[street, overt, imam, father, runs, ties, top,...</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10587</th>\n",
       "      <td>A bit long but a must read Subject Who is Tim ...</td>\n",
       "      <td>[bit, long, must, read, subject, tim, kaine, c...</td>\n",
       "      <td>196</td>\n",
       "      <td>[street, overt, imam, father, runs, ties, top,...</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5325</th>\n",
       "      <td>Yep Americas next Vice President Must read One...</td>\n",
       "      <td>[yep, americas, next, vice, president, must, r...</td>\n",
       "      <td>198</td>\n",
       "      <td>[street, overt, imam, father, runs, ties, top,...</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6703</th>\n",
       "      <td>Hillary wants one world government with a comp...</td>\n",
       "      <td>[hillary, wants, one, world, government, compl...</td>\n",
       "      <td>174</td>\n",
       "      <td>[commit, upon, emigrated, surah, quran, diggin...</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15010</th>\n",
       "      <td>Trump s pledge to the American voter Therefore...</td>\n",
       "      <td>[trump, pledge, american, voter, therefore, fi...</td>\n",
       "      <td>200</td>\n",
       "      <td>[identify, article, foreign, six, allow, must,...</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28164</th>\n",
       "      <td>Bill Clinton cheats on his wife lies under Oat...</td>\n",
       "      <td>[bill, clinton, cheats, wife, lies, oath, rape...</td>\n",
       "      <td>207</td>\n",
       "      <td>[destroy, 700k, leaked, credible, actually, ta...</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28357</th>\n",
       "      <td>Bill Clinton cheats on his wife lies under Oat...</td>\n",
       "      <td>[bill, clinton, cheats, wife, lies, oath, rape...</td>\n",
       "      <td>208</td>\n",
       "      <td>[destroy, 700k, leaked, credible, actually, ta...</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13533</th>\n",
       "      <td>Flashback Interview Trump Defends Gays from Cl...</td>\n",
       "      <td>[flashback, interview, trump, defends, gays, c...</td>\n",
       "      <td>203</td>\n",
       "      <td>[presidential, book, outlines, interviewed, fl...</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15313</th>\n",
       "      <td>Flashback Interview Trump Defends Gays from Cl...</td>\n",
       "      <td>[flashback, interview, trump, defends, gays, c...</td>\n",
       "      <td>203</td>\n",
       "      <td>[presidential, book, outlines, interviewed, fl...</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34178</th>\n",
       "      <td>Sodini revealed that he had purchased a bumper...</td>\n",
       "      <td>[sodini, revealed, purchased, bumper, sticker,...</td>\n",
       "      <td>200</td>\n",
       "      <td>[claim, americans, forced, referring, ties, se...</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39708</th>\n",
       "      <td>STOP THE COUP Phone and fax numbers to the Rep...</td>\n",
       "      <td>[stop, coup, phone, fax, numbers, republicans,...</td>\n",
       "      <td>297</td>\n",
       "      <td>[5136, calling, 801, top, lee, docs, mailbox, ...</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39828</th>\n",
       "      <td>STOP THE COUP Phone and fax numbers to the Rep...</td>\n",
       "      <td>[stop, coup, phone, fax, numbers, republicans,...</td>\n",
       "      <td>297</td>\n",
       "      <td>[5136, calling, 801, top, lee, docs, mailbox, ...</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39903</th>\n",
       "      <td>STOP THE COUP Phone and fax numbers to the Rep...</td>\n",
       "      <td>[stop, coup, phone, fax, numbers, republicans,...</td>\n",
       "      <td>295</td>\n",
       "      <td>[5136, calling, 801, top, lee, docs, mailbox, ...</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39239</th>\n",
       "      <td>and someone else did this earlier but this is ...</td>\n",
       "      <td>[someone, else, earlier, friendly, reminder, d...</td>\n",
       "      <td>289</td>\n",
       "      <td>[5136, presidential, 801, top, directly, lee, ...</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43368</th>\n",
       "      <td>21 Clinton Scandals not a full list of the man...</td>\n",
       "      <td>[clinton, scandals, full, list, many, scandals...</td>\n",
       "      <td>199</td>\n",
       "      <td>[americans, presidential, capitalism, million,...</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46717</th>\n",
       "      <td>November 2016 Donald Trump elected 45th presid...</td>\n",
       "      <td>[november, 2016, donald, trump, elected, 45th,...</td>\n",
       "      <td>221</td>\n",
       "      <td>[high, forced, stand, november, wins, 2017, pe...</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38756</th>\n",
       "      <td>people came to america for a fighting CHANCE 3...</td>\n",
       "      <td>[people, came, america, fighting, chance, 300,...</td>\n",
       "      <td>197</td>\n",
       "      <td>[services, identify, upon, prize, distractions...</td>\n",
       "      <td>182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5827</th>\n",
       "      <td>Id like to grab her right by the pussy I d so ...</td>\n",
       "      <td>[like, grab, right, pussy, love, grab, vagina,...</td>\n",
       "      <td>284</td>\n",
       "      <td>[socket, wuzzy, holster, slit, furnace, combo,...</td>\n",
       "      <td>233</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48455 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Message_clean  \\\n",
       "30563                                                 XD   \n",
       "21554                                            For now   \n",
       "33974                                             Me too   \n",
       "6620                                    All of the above   \n",
       "49690                                                      \n",
       "40142                                                Who   \n",
       "7557                                                 Why   \n",
       "49691                   if if if if if if if if if if if   \n",
       "6148                                             If only   \n",
       "5334                                       She shouldn t   \n",
       "49692                                                 WE   \n",
       "1755                                                       \n",
       "6615               F R E E H E L I C O P T E R R I D E S   \n",
       "38791                                                      \n",
       "39623                                               Se n   \n",
       "47466                                           Who s we   \n",
       "6609                                     d all the above   \n",
       "5346                                                Jo o   \n",
       "49035                                               Will   \n",
       "39617                                   Oh no you di n t   \n",
       "30549                                    W E L L D O N E   \n",
       "10742                                           2 to a 1   \n",
       "51514          C U R R E N T Y E A R U R R E N T Y E A R   \n",
       "51515        S U I C I D E U I C I D E W A T C H A T C H   \n",
       "3477                                                       \n",
       "7995                                                  xD   \n",
       "39602                                                      \n",
       "37073                                                 ok   \n",
       "9070                                                       \n",
       "7576                                        Same with me   \n",
       "...                                                  ...   \n",
       "28393  The Book The experiment military theological S...   \n",
       "10366  A bit long but a must read Subject Who is Tim ...   \n",
       "11160  A bit long but a must read Subject Who is Tim ...   \n",
       "7293   Mine too Must read One step from being Preside...   \n",
       "9496   One step from Potus if Hillary is elected read...   \n",
       "26719  The fact that she has good policies the fact t...   \n",
       "6260   Must read One step from being President Subjec...   \n",
       "9641   One step from Potus if Hillary is elected read...   \n",
       "10097  A bit long but a must read Subject Who is Tim ...   \n",
       "10115  A bit long but a must read Subject Who is Tim ...   \n",
       "10467  A bit long but a must read Subject Who is Tim ...   \n",
       "10486  A bit long but a must read Subject Who is Tim ...   \n",
       "10517  A bit long but a must read Subject Who is Tim ...   \n",
       "10587  A bit long but a must read Subject Who is Tim ...   \n",
       "5325   Yep Americas next Vice President Must read One...   \n",
       "6703   Hillary wants one world government with a comp...   \n",
       "15010  Trump s pledge to the American voter Therefore...   \n",
       "28164  Bill Clinton cheats on his wife lies under Oat...   \n",
       "28357  Bill Clinton cheats on his wife lies under Oat...   \n",
       "13533  Flashback Interview Trump Defends Gays from Cl...   \n",
       "15313  Flashback Interview Trump Defends Gays from Cl...   \n",
       "34178  Sodini revealed that he had purchased a bumper...   \n",
       "39708  STOP THE COUP Phone and fax numbers to the Rep...   \n",
       "39828  STOP THE COUP Phone and fax numbers to the Rep...   \n",
       "39903  STOP THE COUP Phone and fax numbers to the Rep...   \n",
       "39239  and someone else did this earlier but this is ...   \n",
       "43368  21 Clinton Scandals not a full list of the man...   \n",
       "46717  November 2016 Donald Trump elected 45th presid...   \n",
       "38756  people came to america for a fighting CHANCE 3...   \n",
       "5827   Id like to grab her right by the pussy I d so ...   \n",
       "\n",
       "                                                  tokens  token_count  \\\n",
       "30563                                                 []            0   \n",
       "21554                                                 []            0   \n",
       "33974                                                 []            0   \n",
       "6620                                                  []            0   \n",
       "49690                                                 []            0   \n",
       "40142                                                 []            0   \n",
       "7557                                                  []            0   \n",
       "49691                                                 []            0   \n",
       "6148                                                  []            0   \n",
       "5334                                                  []            0   \n",
       "49692                                                 []            0   \n",
       "1755                                                  []            0   \n",
       "6615                                                  []            0   \n",
       "38791                                                 []            0   \n",
       "39623                                                 []            0   \n",
       "47466                                                 []            0   \n",
       "6609                                                  []            0   \n",
       "5346                                                  []            0   \n",
       "49035                                                 []            0   \n",
       "39617                                                 []            0   \n",
       "30549                                                 []            0   \n",
       "10742                                                 []            0   \n",
       "51514                                                 []            0   \n",
       "51515                                                 []            0   \n",
       "3477                                                  []            0   \n",
       "7995                                                  []            0   \n",
       "39602                                                 []            0   \n",
       "37073                                                 []            0   \n",
       "9070                                                  []            0   \n",
       "7576                                                  []            0   \n",
       "...                                                  ...          ...   \n",
       "28393  [book, experiment, military, theological, s666...          217   \n",
       "10366  [bit, long, must, read, subject, tim, kaine, c...          196   \n",
       "11160  [bit, long, must, read, subject, tim, kaine, c...          196   \n",
       "7293   [mine, must, read, one, step, president, subje...          196   \n",
       "9496   [one, step, potus, hillary, elected, read, sub...          196   \n",
       "26719  [fact, good, policies, fact, fit, potus, email...          180   \n",
       "6260   [must, read, one, step, president, subject, ti...          197   \n",
       "9641   [one, step, potus, hillary, elected, read, sub...          196   \n",
       "10097  [bit, long, must, read, subject, tim, kaine, c...          196   \n",
       "10115  [bit, long, must, read, subject, tim, kaine, c...          196   \n",
       "10467  [bit, long, must, read, subject, tim, kaine, c...          196   \n",
       "10486  [bit, long, must, read, subject, tim, kaine, c...          196   \n",
       "10517  [bit, long, must, read, subject, tim, kaine, c...          196   \n",
       "10587  [bit, long, must, read, subject, tim, kaine, c...          196   \n",
       "5325   [yep, americas, next, vice, president, must, r...          198   \n",
       "6703   [hillary, wants, one, world, government, compl...          174   \n",
       "15010  [trump, pledge, american, voter, therefore, fi...          200   \n",
       "28164  [bill, clinton, cheats, wife, lies, oath, rape...          207   \n",
       "28357  [bill, clinton, cheats, wife, lies, oath, rape...          208   \n",
       "13533  [flashback, interview, trump, defends, gays, c...          203   \n",
       "15313  [flashback, interview, trump, defends, gays, c...          203   \n",
       "34178  [sodini, revealed, purchased, bumper, sticker,...          200   \n",
       "39708  [stop, coup, phone, fax, numbers, republicans,...          297   \n",
       "39828  [stop, coup, phone, fax, numbers, republicans,...          297   \n",
       "39903  [stop, coup, phone, fax, numbers, republicans,...          295   \n",
       "39239  [someone, else, earlier, friendly, reminder, d...          289   \n",
       "43368  [clinton, scandals, full, list, many, scandals...          199   \n",
       "46717  [november, 2016, donald, trump, elected, 45th,...          221   \n",
       "38756  [people, came, america, fighting, chance, 300,...          197   \n",
       "5827   [like, grab, right, pussy, love, grab, vagina,...          284   \n",
       "\n",
       "                                             uniq_tokens  uniq_tokens_count  \n",
       "30563                                                 []                  0  \n",
       "21554                                                 []                  0  \n",
       "33974                                                 []                  0  \n",
       "6620                                                  []                  0  \n",
       "49690                                                 []                  0  \n",
       "40142                                                 []                  0  \n",
       "7557                                                  []                  0  \n",
       "49691                                                 []                  0  \n",
       "6148                                                  []                  0  \n",
       "5334                                                  []                  0  \n",
       "49692                                                 []                  0  \n",
       "1755                                                  []                  0  \n",
       "6615                                                  []                  0  \n",
       "38791                                                 []                  0  \n",
       "39623                                                 []                  0  \n",
       "47466                                                 []                  0  \n",
       "6609                                                  []                  0  \n",
       "5346                                                  []                  0  \n",
       "49035                                                 []                  0  \n",
       "39617                                                 []                  0  \n",
       "30549                                                 []                  0  \n",
       "10742                                                 []                  0  \n",
       "51514                                                 []                  0  \n",
       "51515                                                 []                  0  \n",
       "3477                                                  []                  0  \n",
       "7995                                                  []                  0  \n",
       "39602                                                 []                  0  \n",
       "37073                                                 []                  0  \n",
       "9070                                                  []                  0  \n",
       "7576                                                  []                  0  \n",
       "...                                                  ...                ...  \n",
       "28393  [tarot, sasso, book, roman, street, november, ...                152  \n",
       "10366  [street, overt, imam, father, runs, ties, top,...                153  \n",
       "11160  [street, overt, imam, father, runs, ties, top,...                153  \n",
       "7293   [street, overt, imam, father, runs, ties, top,...                153  \n",
       "9496   [street, overt, imam, father, runs, ties, top,...                153  \n",
       "26719  [fit, americans, collectively, stance, entirel...                153  \n",
       "6260   [street, overt, imam, father, runs, ties, top,...                153  \n",
       "9641   [street, overt, imam, father, runs, ties, top,...                153  \n",
       "10097  [street, overt, imam, father, runs, ties, top,...                153  \n",
       "10115  [street, overt, imam, father, runs, ties, top,...                153  \n",
       "10467  [street, overt, imam, father, runs, ties, top,...                153  \n",
       "10486  [street, overt, imam, father, runs, ties, top,...                153  \n",
       "10517  [street, overt, imam, father, runs, ties, top,...                153  \n",
       "10587  [street, overt, imam, father, runs, ties, top,...                153  \n",
       "5325   [street, overt, imam, father, runs, ties, top,...                154  \n",
       "6703   [commit, upon, emigrated, surah, quran, diggin...                155  \n",
       "15010  [identify, article, foreign, six, allow, must,...                155  \n",
       "28164  [destroy, 700k, leaked, credible, actually, ta...                159  \n",
       "28357  [destroy, 700k, leaked, credible, actually, ta...                159  \n",
       "13533  [presidential, book, outlines, interviewed, fl...                163  \n",
       "15313  [presidential, book, outlines, interviewed, fl...                163  \n",
       "34178  [claim, americans, forced, referring, ties, se...                164  \n",
       "39708  [5136, calling, 801, top, lee, docs, mailbox, ...                168  \n",
       "39828  [5136, calling, 801, top, lee, docs, mailbox, ...                168  \n",
       "39903  [5136, calling, 801, top, lee, docs, mailbox, ...                169  \n",
       "39239  [5136, presidential, 801, top, directly, lee, ...                169  \n",
       "43368  [americans, presidential, capitalism, million,...                169  \n",
       "46717  [high, forced, stand, november, wins, 2017, pe...                171  \n",
       "38756  [services, identify, upon, prize, distractions...                182  \n",
       "5827   [socket, wuzzy, holster, slit, furnace, combo,...                233  \n",
       "\n",
       "[48455 rows x 5 columns]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On se rend compte que les messages de moins de 2 tokens sont interessant a analiser. Donc on les elimines pas\n",
    "# print(df.columns)\n",
    "print(df.columns)\n",
    "df[0:5]\n",
    "df.sort_values(by = 'uniq_tokens_count', ascending = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NUMERISATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(35065 unique tokens: ['like', 'share', 'studded', 'trump', 'banner']...)\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim import corpora, models\n",
    "\n",
    "# Dictionnaire de tous les tokens, faire attention de choisir si on vuet les tokens ou les uniq_tokens\n",
    "dictionary  = corpora.Dictionary(df.uniq_tokens)\n",
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     [(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1)]\n",
      "1    [(0, 1), (3, 1), (6, 1), (7, 1), (8, 1), (9, 1...\n",
      "3    [(143, 1), (144, 1), (145, 1), (146, 1), (147,...\n",
      "4    [(0, 1), (3, 1), (6, 1), (7, 1), (8, 1), (9, 1...\n",
      "5    [(149, 1), (150, 1), (151, 1), (152, 1), (153,...\n",
      "Name: corpus2, dtype: object\n"
     ]
    }
   ],
   "source": [
    "df['corpus2'] = df.uniq_tokens.apply(lambda d : dictionary.doc2bow(d))\n",
    "\n",
    "print(df['corpus2'] .head())\n",
    "\n",
    "# aggreger les rows\n",
    "\n",
    "corpus2 = [c for c in df.corpus2 ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== topic #0\n",
      "0.030: pence,  0.015: matt,  0.010: holy,  0.009: fat,  0.009: savage,  0.009: killed,  0.009: alexander,  0.008: justin,  0.007: van,  0.007: accurate\n",
      "\n",
      "=== topic #1\n",
      "0.016: jack,  0.015: agree,  0.014: jordan,  0.012: kevin,  0.012: evil,  0.012: dan,  0.012: mate,  0.012: tim,  0.011: republican,  0.011: bernie\n",
      "\n",
      "=== topic #2\n",
      "0.038: women,  0.037: michael,  0.027: hahaha,  0.022: men,  0.020: matthew,  0.019: luke,  0.018: yet,  0.018: george,  0.016: saw,  0.015: william\n",
      "\n",
      "=== topic #3\n",
      "0.040: got,  0.033: take,  0.033: pussy,  0.030: josh,  0.023: youtu,  0.021: years,  0.019: https,  0.016: important,  0.016: grab,  0.016: adam\n",
      "\n",
      "=== topic #4\n",
      "0.050: better,  0.036: kaine,  0.034: folks,  0.034: gon,  0.025: used,  0.024: happen,  0.021: since,  0.021: lot,  0.018: time,  0.015: pay\n",
      "\n",
      "=== topic #5\n",
      "0.050: real,  0.038: alex,  0.035: james,  0.032: ryan,  0.032: white,  0.023: always,  0.021: end,  0.020: picture,  0.018: dead,  0.016: low\n",
      "\n",
      "=== topic #6\n",
      "0.037: ben,  0.037: saying,  0.032: little,  0.031: ever,  0.029: post,  0.029: put,  0.024: chris,  0.024: campaign,  0.016: robert,  0.016: means\n",
      "\n",
      "=== topic #7\n",
      "0.022: daniel,  0.021: austin,  0.020: else,  0.018: paul,  0.018: getting,  0.018: jacob,  0.017: reason,  0.016: scott,  0.015: watching,  0.015: joseph\n",
      "\n",
      "=== topic #8\n",
      "0.061: time,  0.042: andrew,  0.040: yeah,  0.029: much,  0.026: next,  0.023: jones,  0.021: far,  0.020: remember,  0.019: person,  0.017: first\n",
      "\n",
      "=== topic #9\n",
      "0.220: lol,  0.029: cuck,  0.025: dont,  0.014: candidate,  0.012: orange,  0.012: symbol,  0.010: presidential,  0.010: cancer,  0.009: freedom,  0.009: countries\n",
      "\n",
      "=== topic #10\n",
      "0.057: want,  0.040: back,  0.031: point,  0.030: last,  0.021: energy,  0.020: probably,  0.020: part,  0.020: become,  0.020: high,  0.019: head\n",
      "\n",
      "=== topic #11\n",
      "0.046: nothing,  0.038: tom,  0.037: american,  0.027: instead,  0.026: omg,  0.023: jake,  0.020: another,  0.017: seriously,  0.016: hilary,  0.015: difference\n",
      "\n",
      "=== topic #12\n",
      "0.079: fucking,  0.061: trump,  0.057: vote,  0.046: let,  0.045: donald,  0.027: facebook,  0.025: done,  0.024: ass,  0.022: whole,  0.021: thats\n",
      "\n",
      "=== topic #13\n",
      "0.088: pepe,  0.056: meme,  0.039: never,  0.036: going,  0.035: call,  0.031: debate,  0.030: come,  0.029: year,  0.023: fact,  0.022: night\n",
      "\n",
      "=== topic #14\n",
      "0.062: get,  0.052: said,  0.028: wall,  0.025: live,  0.022: keep,  0.021: oliver,  0.015: guess,  0.014: maybe,  0.014: black,  0.014: muslims\n",
      "\n",
      "=== topic #15\n",
      "0.077: clinton,  0.032: war,  0.029: hillary,  0.025: hard,  0.023: least,  0.023: world,  0.021: around,  0.020: state,  0.019: video,  0.015: taxes\n",
      "\n",
      "=== topic #16\n",
      "0.067: president,  0.042: win,  0.036: called,  0.020: trump,  0.018: whatever,  0.018: americans,  0.014: allowed,  0.013: 100,  0.013: given,  0.011: polls\n",
      "\n",
      "=== topic #17\n",
      "0.040: big,  0.036: tell,  0.023: rape,  0.019: full,  0.016: raped,  0.015: russia,  0.014: amy,  0.013: wanted,  0.013: help,  0.013: absolutely\n",
      "\n",
      "=== topic #18\n",
      "0.049: hillary,  0.032: trump,  0.027: media,  0.025: hope,  0.024: people,  0.022: thought,  0.017: putin,  0.016: voting,  0.016: would,  0.015: use\n",
      "\n",
      "=== topic #19\n",
      "0.076: fuck,  0.073: true,  0.064: guy,  0.035: sure,  0.033: pretty,  0.033: obama,  0.029: wrong,  0.028: kek,  0.025: bad,  0.024: life\n",
      "\n",
      "=== topic #20\n",
      "0.096: good,  0.038: http,  0.037: 2016,  0.034: page,  0.031: trump,  0.029: someone,  0.027: com,  0.024: old,  0.018: free,  0.018: tho\n",
      "\n",
      "=== topic #21\n",
      "0.060: still,  0.039: way,  0.039: every,  0.037: many,  0.032: needs,  0.028: country,  0.026: people,  0.025: talking,  0.024: trying,  0.021: gets\n",
      "\n",
      "=== topic #22\n",
      "0.056: thing,  0.049: see,  0.048: even,  0.031: everyone,  0.027: support,  0.026: dude,  0.023: stupid,  0.019: like,  0.019: anyone,  0.019: race\n",
      "\n",
      "=== topic #23\n",
      "0.168: like,  0.102: shit,  0.055: look,  0.045: looks,  0.027: show,  0.020: bitch,  0.016: start,  0.012: office,  0.011: using,  0.010: strong\n",
      "\n",
      "=== topic #24\n",
      "0.069: lmao,  0.042: best,  0.039: david,  0.031: john,  0.028: everything,  0.027: feel,  0.021: sam,  0.020: peter,  0.017: dylan,  0.014: sorry\n",
      "\n",
      "=== topic #25\n",
      "0.072: https,  0.070: com,  0.061: watch,  0.056: www,  0.039: youtube,  0.025: gay,  0.022: taylor,  0.012: job,  0.009: gary,  0.008: class\n",
      "\n",
      "=== topic #26\n",
      "0.157: one,  0.100: think,  0.038: guys,  0.030: read,  0.025: enough,  0.025: give,  0.022: know,  0.021: knows,  0.017: away,  0.017: good\n",
      "\n",
      "=== topic #27\n",
      "0.073: supporter,  0.064: sent,  0.033: mike,  0.025: woman,  0.025: nick,  0.025: trump,  0.025: supporters,  0.025: talk,  0.021: damn,  0.019: liberal\n",
      "\n",
      "=== topic #28\n",
      "0.120: right,  0.037: left,  0.028: new,  0.024: literally,  0.022: hitler,  0.012: levi,  0.012: toledo,  0.011: male,  0.011: boy,  0.010: bailey\n",
      "\n",
      "=== topic #29\n",
      "0.096: make,  0.076: great,  0.064: america,  0.047: memes,  0.040: sad,  0.033: racist,  0.028: kill,  0.022: lmfao,  0.021: wikileaks,  0.021: find\n",
      "\n",
      "=== topic #30\n",
      "0.045: please,  0.031: must,  0.027: truth,  0.024: problem,  0.018: share,  0.014: bush,  0.010: calum,  0.010: politics,  0.009: macrae,  0.009: europe\n",
      "\n",
      "=== topic #31\n",
      "0.055: though,  0.042: stop,  0.027: dumb,  0.021: try,  0.017: honestly,  0.013: gun,  0.011: completely,  0.010: exist,  0.009: louis,  0.008: logan\n",
      "\n",
      "=== topic #32\n",
      "0.095: god,  0.050: emperor,  0.042: trump,  0.041: things,  0.017: law,  0.016: coming,  0.015: isis,  0.014: thomas,  0.013: future,  0.013: empire\n",
      "\n",
      "=== topic #33\n",
      "0.036: face,  0.030: says,  0.025: cnn,  0.022: release,  0.018: emails,  0.017: jay,  0.015: yup,  0.015: raymond,  0.015: across,  0.014: loves\n",
      "\n",
      "=== topic #34\n",
      "0.080: say,  0.080: man,  0.061: well,  0.053: actually,  0.043: anything,  0.018: seen,  0.017: could,  0.014: trump,  0.013: story,  0.013: harambe\n",
      "\n",
      "=== topic #35\n",
      "0.029: top,  0.027: election,  0.027: thanks,  0.024: nice,  0.018: thinking,  0.017: days,  0.017: poor,  0.016: cause,  0.016: hours,  0.015: took\n",
      "\n",
      "=== topic #36\n",
      "0.090: love,  0.068: need,  0.057: haha,  0.026: wait,  0.025: already,  0.023: wow,  0.015: etc,  0.014: kids,  0.012: vult,  0.010: stephen\n",
      "\n",
      "=== topic #37\n",
      "0.054: made,  0.047: really,  0.045: bill,  0.040: mean,  0.034: day,  0.032: funny,  0.032: assange,  0.020: hell,  0.015: making,  0.014: internet\n",
      "\n",
      "=== topic #38\n",
      "0.041: believe,  0.041: yes,  0.039: hate,  0.036: like,  0.036: something,  0.032: also,  0.019: liberals,  0.018: tax,  0.017: gays,  0.014: matter\n"
     ]
    }
   ],
   "source": [
    "num_topics= 39\n",
    "\n",
    "# Le model LDA\n",
    "lda = models.LdaModel(corpus2,\n",
    "    id2word=dictionary,\n",
    "    num_topics=num_topics,\n",
    "    alpha = 'asymmetric',\n",
    "    eta='auto',\n",
    "    passes = 2,\n",
    "    iterations = 20\n",
    ")\n",
    "\n",
    "\n",
    "for t in lda.show_topics(num_topics=num_topics, formatted=True, log = False):\n",
    "    print(\"\\n=== topic #{}\".format(t[0]))\n",
    "    print(t[1].replace('*', ': ').replace(' +',', ').replace('\"',''))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
